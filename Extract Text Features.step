{"creationTimeStamp":"2022-09-18T16:31:44.785Z","modifiedTimeStamp":"2022-10-24T08:14:10.555Z","createdBy":"viyademo01","modifiedBy":"viyademo01","name":"Extract Text Features.step","displayName":"Extract Text Features.step","localDisplayName":"Extract Text Features.step","properties":{},"links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","uri":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","uri":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","uri":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","uri":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","uri":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","uri":"/dataFlows/steps/29a1d694-afc4-4c0a-8465-611fe9601864","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":0.0,"version":2,"type":"code","flowMetadata":{"inputPorts":[{"name":"inTable","displayName":"inTable","localDisplayName":"inTable","minEntries":1,"maxEntries":1,"type":"table"},{"name":"custConInTable","displayName":"custConInTable","localDisplayName":"custConInTable","minEntries":0,"maxEntries":1,"type":"table"}],"outputPorts":[{"name":"outTable","displayName":"outTable","localDisplayName":"outTable","minEntries":1,"maxEntries":1,"type":"table","requiresStructure":false},{"name":"outTableRexExContext","displayName":"outTableRexExContext","localDisplayName":"outTableRexExContext","minEntries":0,"maxEntries":1,"type":"table","requiresStructure":false}]},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"page1\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Base Metadata\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"inTable\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input Table containing your Text\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"outTable\",\n\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\"label\": \"Output Table containing the additional Features\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text1\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The step extracts features from your Text.\\n\\nAll variables created start with _etm.\\n\\nThis step only works with SAS Base Engine tables.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textCol\",\n\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\"label\": \"Select the column that contains the Text:\",\n\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\"columntype\": \"c\",\n\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createPercentUsed\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to create a percentage of the used available characters?\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"maxCharsAllowed\",\n\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\"label\": \"How many characters are allowed?\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\"visible\": \"$createPercentUsed\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text2\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"For the Extraction of User Mentions, Hashtags and Links there is four stages that build on top of each other:\\n1. A count per Text of the Feature\\n2. A concatenated Column of the Feature per Text\\n3. A separate column for each Feature per Text (this is non-unique, there will be n columns created depending on the most Features found in one Text)\\n4. Create Co-Occurrence column for the top Features\\nYou need to accept the concatenated columns in order to get the ability to have the concatenated values separated in their own columns and to create Co-Occurrences.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section5\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extract User Mentions\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createUserMentions\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to extract a Count of User Mentions (@)?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"concatAtSigns\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concatenated Column of all User Mentions per Text?\",\n\t\t\t\t\t\t\t\"visible\": \"$createUserMentions\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleAtSigns\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create separated columns for User Mentions?\",\n\t\t\t\t\t\t\t\"visible\": \"$concatAtSigns\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createAtOccurences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create Co-Occurrences for User Mentions?\",\n\t\t\t\t\t\t\t\"visible\": \"$singleAtSigns\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfAtOccurences\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Times a User has to be mentioned to be counted as a significant Co-Occurrence\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createAtOccurences\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfAtOutputs\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Limit the number of Co-Occurrences for User Mentions to the Top (highly suggested to reduce dataset size):\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createAtOccurences\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section1\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extract Hashtags\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createHashtags\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to extract a Count of Hashtags (#)?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"concatHashtags\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concatenated Column of all Hashtags per Text?\",\n\t\t\t\t\t\t\t\"visible\": \"$createHashtags\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleHashtags\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create separated columns for Hashtags?\",\n\t\t\t\t\t\t\t\"visible\": \"$concatHashtags\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createHTOccurences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create Co-Occurrences for Hashtags?\",\n\t\t\t\t\t\t\t\"visible\": \"$singleHashtags\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfHTOccurences\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Times a Hashtags has to be mentioned to be counted as a significant Co-Occurrence\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createHTOccurences\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfHTOutputs\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Limit the number of Co-Occurrences for Hashtags to the Top (highly suggested to reduce dataset size):\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createHTOccurences\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section6\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extract Links\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text7\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please note that for the Link Data page options to unlock you have to create a concatenated column and separated columns for the links here.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createLinks\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to extract a Count of Links (http)?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"concatLinks\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concatenated Column of all Links per Text?\",\n\t\t\t\t\t\t\t\"visible\": \"$createLinks\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleLinks\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create separated columns for Links?\",\n\t\t\t\t\t\t\t\"visible\": \"$concatLinks\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createLKOccurences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create Co-Occurrences for Links?\",\n\t\t\t\t\t\t\t\"visible\": \"$singleLinks\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfLKOccurences\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Times a Links has to be mentioned to be counted as a significant Co-Occurrence\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createLKOccurences\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfLKOutputs\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Limit the number of Co-Occurrences for Links Mentions to the Top (highly suggested to reduce dataset size):\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createLKOccurences\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page5\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Custom RegEx Pattern\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text8\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"This page enables you to extract your own custom feature based on a RegEx pattern.\\n\\nPlease ensure that you enter a valid RegEx pattern. You can use the SAS data step function prxparse to check the validity of your pattern.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"extractCustomRegEx\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to extract a custom RegEx Pattern from the text?\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"prxPattern\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"Please enter a valid RegEx pattern here - you have to enclose it in / and you can specify a RegEx Flag:\",\n\t\t\t\t\t\"placeholder\": \"/test/i\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"minDocCnt\",\n\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\"label\": \"Only create a Feature if the Pattern occurs n times:\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createCustomRegExGraphics\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Add Tables summarizing the findings to the Results\",\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section9\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Snippet Context Window for the Pattern (Optional)\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text10\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Enables you to create an additional output table the contains next to the extracted pattern some surrounding text to better enable you to judge if your pattern worked as you intended.\\n\\nTo enter a custom name for this table please right click the step in the flow > Expand Output Ports and then connect your desired output table to the new port.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createSnippetTable\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create an additional table containing some context around the found RegEx Pattern?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"snipplet_window\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of characters extracte before and after the Occurrence:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createSnippetTable\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"outTableRexExContext\",\n\t\t\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\t\t\"label\": \"RegEx Context Table Output\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"work._etm_regex_context\",\n\t\t\t\t\t\t\t\"visible\": \"$createSnippetTable\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section8\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Feature Association with Target (Optional)\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text9\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"If you have a numerical binary target variable with values 0 and 1 then you can create additional statistics to show the association of the target level with the feature.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"regExTargetCheck\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you have a binary numeric Target variable?\",\n\t\t\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"regExTarget\",\n\t\t\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\t\t\"label\": \"Please select the Target variable from the Input Data Set:\",\n\t\t\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\t\t\"columntype\": \"n\",\n\t\t\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$regExTargetCheck\",\n\t\t\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"minTgMean\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Minimum Target Mean:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": false,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 10,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$regExTargetCheck\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxTgMean\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Maximum Target Mean\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 10,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$regExTargetCheck\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page3\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Link Data\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text4\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Collect additional information from the links in the tweets. This option requires you to have enabled the Options for concatenated and separated columns.\\n\\nPlease note for this step to work your environment needs to be able to make calls to the open internet.\\n\\nPlease be also aware that this step can take a lot of time to run as the individual sites have to be called and their output need to be parsed.\\n\\nThe following five features are extracted for each link:\\n- HTTP Status Code (basically is it reachable or not)\\n- Title of the Webpage\\n- Description of the Webpage\\n- URL of the Webpage (handy if URL shorteners were used\\n- Owner of the site\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"getLinkMetadata\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to collect metadata from Links in the text?\",\n\t\t\t\t\t\"visible\": \"$singleLinks\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"allowUnverifiedRequests\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to allow Unverified Requests (Warning potential impact: Breach of Confidentiality & Breach of Integrity)?\",\n\t\t\t\t\t\"visible\": \"$getLinkMetadata\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"urlLimiter\",\n\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\"label\": \"Limit the number of Links to the Top:\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\"visible\": \"$getLinkMetadata\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page4\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Text Analytics - Start\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text5\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The additional information derived here is only available if you have SAS Visual Text Analytics licensed.\\n\\nTo detect the sentiment and extract text topics you have to select the language detection option.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"useTextAnalytics\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to use Text Analytics? (license required)\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"howLanguage\",\n\t\t\t\t\t\"type\": \"radiogroup\",\n\t\t\t\t\t\"label\": \"Do you want to automatically detect the text language?\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"1\",\n\t\t\t\t\t\t\t\"label\": \"Yes\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"0\",\n\t\t\t\t\t\t\t\"label\": \"No\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"userSpecifiedLanguage\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Please select the language of your text:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ar\",\n\t\t\t\t\t\t\t\"label\": \"Arabic\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"zh\",\n\t\t\t\t\t\t\t\"label\": \"Chinese\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"hr\",\n\t\t\t\t\t\t\t\"label\": \"Croatian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"cs\",\n\t\t\t\t\t\t\t\"label\": \"Czech\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"da\",\n\t\t\t\t\t\t\t\"label\": \"Danish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"nl\",\n\t\t\t\t\t\t\t\"label\": \"Dutch\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"en\",\n\t\t\t\t\t\t\t\"label\": \"English\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"fi\",\n\t\t\t\t\t\t\t\"label\": \"Finnish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"fr\",\n\t\t\t\t\t\t\t\"label\": \"French\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"de\",\n\t\t\t\t\t\t\t\"label\": \"German\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"el\",\n\t\t\t\t\t\t\t\"label\": \"Greek\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"iw\",\n\t\t\t\t\t\t\t\"label\": \"Hebrew\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"hi\",\n\t\t\t\t\t\t\t\"label\": \"Hindi\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"hu\",\n\t\t\t\t\t\t\t\"label\": \"Hungarian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"in\",\n\t\t\t\t\t\t\t\"label\": \"Indonesian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"it\",\n\t\t\t\t\t\t\t\"label\": \"Italian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ja\",\n\t\t\t\t\t\t\t\"label\": \"Japanese\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"kk\",\n\t\t\t\t\t\t\t\"label\": \"Kazakh\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ko\",\n\t\t\t\t\t\t\t\"label\": \"Korean\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"no\",\n\t\t\t\t\t\t\t\"label\": \"Norwegian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"fa\",\n\t\t\t\t\t\t\t\"label\": \"Persian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"pl\",\n\t\t\t\t\t\t\t\"label\": \"Polish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"pt\",\n\t\t\t\t\t\t\t\"label\": \"Portuguese\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ro\",\n\t\t\t\t\t\t\t\"label\": \"Romanian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ru\",\n\t\t\t\t\t\t\t\"label\": \"Russian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"sk\",\n\t\t\t\t\t\t\t\"label\": \"Slovak\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"sl\",\n\t\t\t\t\t\t\t\"label\": \"Slovene\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"es\",\n\t\t\t\t\t\t\t\"label\": \"Spanish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"sv\",\n\t\t\t\t\t\t\t\"label\": \"Swedish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"tl\",\n\t\t\t\t\t\t\t\"label\": \"Tagalog\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"th\",\n\t\t\t\t\t\t\t\"label\": \"Thai\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"tr\",\n\t\t\t\t\t\t\t\"label\": \"Turkish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"vi\",\n\t\t\t\t\t\t\t\"label\": \"Vietnamese\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\"$useTextAnalytics\",\n\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\"$howLanguage\",\n\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\"0\"\n\t\t\t\t\t\t]\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createLanguagePlot\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Create Plot of Detected Languages\",\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\"$howLanguage\",\n\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\"1\"\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\"$useTextAnalytics\"\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section7\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Text Profiling\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"profileText\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to profile your text?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"compareReferenceCorpus\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Compare your text corpus to reference corpus profiles (Not available for all languages yet, raises a warning accordingly)\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createProfileTextGraphs\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Add Word and Sentence count per Document and Language to the Results\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createNumSentences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create a feature for the number of sentences in the Text\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createMaxTokenSentence\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create a feature for the count of tokens in the longest sentence\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section2\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Sentiment detection\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"detectSentiment\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to detect the text sentiment?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createSentimentPlot\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Plot of Sentiment by Languages\",\n\t\t\t\t\t\t\t\"visible\": \"$detectSentiment\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section4\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Text Concept Extraction\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text13\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Selecting SAS Predefined Concepts also enables you to use these as features in the customization options for the Text Topic Creation.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createPredefinedConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to apply the SAS Predefined Concepts?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"conceptList\",\n\t\t\t\t\t\t\t\"type\": \"list\",\n\t\t\t\t\t\t\t\"label\": \"Select Predefined Concepts you wish applied to your text:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpDate\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Date\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpMeasure\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Measure\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpMoney\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Money\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpNounGroup\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Noun Group\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpOrganization\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Organization\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpPercent\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Percent\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpPerson\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Person\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpPlace\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Place\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpTime\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Time\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"max\": 9,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"visible\": \"$createPredefinedConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createPreConceptPlot\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Plot of Extracted SAS Predefined Concepts for each Language\",\n\t\t\t\t\t\t\t\"visible\": \"$createPredefinedConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createConcatedPreConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concated column of all matched text for each pre defined concept type?\",\n\t\t\t\t\t\t\t\"visible\": \"$createPredefinedConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singlePreConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want SAS Pre Defined Concepts as seperated columns?\",\n\t\t\t\t\t\t\t\"visible\": \"$createConcatedPreConcepts\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section10\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Custom Text Concept Extraction\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text11\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please ensure that you have validated your Custom Concepts before using this step.\\n\\nTo add the table containing your Custom Concepts right click the step in the flow > Expand Input Ports and then connect your desired input table to the new port.\\n\\nSupplying your own Custom Concepts also enables you to use these features in the customization options for the Text Topic Creation.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"useCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to apply custom concepts?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"custConInTable\",\n\t\t\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\t\t\"label\": \"Please add an input table containg your Custom Concepts\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"work.custom_concepts\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"compiledCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Are your concepts already compiled?\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"customConInTable\",\n\t\t\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\t\t\"label\": \"Please select the column containing the custom concept\",\n\t\t\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\t\t\"columntype\": \"c\",\n\t\t\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\",\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\"!$compiledCustomConcepts\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"table\": \"custConInTable\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createCustomConceptPlot\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Plot of Extracted Custom Concepts for each Language\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createConcatedCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concated column of all matched text for each Custom Concept?\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want Custom Concepts as seperated columns?\",\n\t\t\t\t\t\t\t\"visible\": \"$createConcatedCustomConcepts\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page6\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Text Analytics - Topic Creation\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text12\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The additional information derived here is only available if you have SAS Visual Text Analytics licensed.\\n\\nTopics are created for all languages that have more 50 or more rows in the dataset.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createTopics\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to have Topics created for you?\",\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"useBestPractise\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want us the Text Topic Creation Best Practise?\",\n\t\t\t\t\t\"visible\": \"$createTopics\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section3\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Parse Text\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"!$useBestPractise\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"posTagging\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Include Parts of Speech\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"extractNounGroups\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Extract Noun Groups\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"extractEntities\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Extract Entities\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"stemTerms\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Stem Terms\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"minOccKeep\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Minimum number of occurrences to keep a term:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"cellWeight\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Use the log to weight the cells of the term-by-document matrix\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"termWeight\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Weight terms by:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"entropy\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Entropy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"mi\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Mutual Information\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"none\",\n\t\t\t\t\t\t\t\t\t\"label\": \"No weighting\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"useStopWords\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to use a stop word list?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"normProjects\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Normalize the Document Projections, Term Projections, or Both:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"all\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Both\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"doc\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Document\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"word\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Word\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"none\",\n\t\t\t\t\t\t\t\t\t\"label\": \"None\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section12\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Discover Topics\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"!$useBestPractise\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numTopics\",\n\t\t\t\t\t\t\t\"type\": \"radiogroup\",\n\t\t\t\t\t\t\t\"label\": \"How to discover Topics:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"0\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Specify number of Topics\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"1\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Recommend number of topics\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numTopicsK\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of topics:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 1000,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$numTopics\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"0\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numTopicsMaxK\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Maximum number of topics:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 1000,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$numTopics\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"1\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"resolutionLevel\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Desired Resolution Level for the recommended Number of Dimensions to be extracted by the SVD:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"low\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Low\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"med\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Medium\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"high\",\n\t\t\t\t\t\t\t\t\t\"label\": \"High\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"rotationType\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Type of Rotation used to Maximize the Explanatory Power of each Topic\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"varimax\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Uncorrelated Topics (Varimax)\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"promax\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Correlated Topics (Promax)\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numLabels\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of Terms to use in the Descriptive Label for each Topic\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 500,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"selectEntities\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"List of Entity Types to be kept - All of the SAS Predefined Concepts and Custom Concepts that you included will be used if selected\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$createPredefinedConcepts\",\n\t\t\t\t\t\t\t\t\"|\",\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"defaultEntityPrio\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Set the Default Entity Priority:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 31,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$selectEntities\",\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"hasCustomPrio\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Does your table containg the compiled Custom Concepts contain a column named _priority_? If not a the priority is calculated as Defaulit Entity Priority + 1.\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$selectEntities\",\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section11\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Plots\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$createTopics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createScreePlotSVD\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Scree Plots of the SVD for each language\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page7\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Text Analytics - Bool Rule Creation\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text6\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The additional information derived here is only available if you have SAS Visual Text Analytics licensed.\\n\\nPlease note that BoolRule creation can have significant target leakage, but it can be generate powerful features. Often times it is useful to check the created rules and abstract them into custom concepts or a RegEx pattern.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createBoolRules\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to leverage BoolRule Creation to create additional Features?\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"useTopicCreationTbD\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want use the Term-by-Document Matrix from the Topic Creation?\",\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\"$createTopics\",\n\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\"$createBoolRules\"\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"boolRuleTarget\",\n\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\"label\": \"Please select a target variable:\",\n\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\"columntype\": \"a\",\n\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"visible\": \"$createBoolRules\",\n\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"boolRuleTargetType\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Please select the Type of your Target Variable:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"Binary\",\n\t\t\t\t\t\t\t\"label\": \"Binary\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"Multiclass\",\n\t\t\t\t\t\t\t\"label\": \"Multiclass\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"Multilabel\",\n\t\t\t\t\t\t\t\"label\": \"Multilabel\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"$createBoolRules\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section13\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Customization\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$createBoolRules\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"gPosBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Minimum G-Score needed for a Positive Term to be considered for Rule Extraction:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"mPosBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the M Value for computing Estimated Precision for Positive Terms:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"gNegBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Minimum G-Score needed for a Negative Term to be considered for Rule Extraction:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"mNegBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the M Value for computing Estimated Precision for Negative Terms:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"minSupportsBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Minimum Number of Documents in which a Term needs to appear in order for the Term to be used for creating a Rule:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxCandidatesBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Number of Term Candidates to be selected for each Category:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxTriesInBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the K-In Value for K-Best Search in the Term Ensemble Process for Creating Rules:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxTriesOutBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the K-Out Value for K-Best Search in the Term Ensemble Process for Creating Rules:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page2\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Information\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text3\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The output always contains the following for each Text:\\n- Number of Full Stops\\n- Number of Questions Marks\\n- Number of Exclamation Points\\n- Number of User Mentions\\n- Number of Hashtags\\n- Number of Links\\n- Total Word Count\\n- Total Character Count\\n\\nIf you use the of the Additional Metadata or Text Analytics features a unique ID is generated for your text called _etm_ID.\\n\\nFor more information about the algorithms and parameters please take a look at the SAS documentation site: https://documentation.sas.com/?cdcId=pgmsascdc&cdcVersion=default&docsetId=casvtapg&docsetTarget=n1tlj0l2pvf92vn1ruide9yikmlo.htm\\n\\nThis custom step was created in collaboration between:\\n- David.Weik@sas.com\\n- Ulrich.Reincke@sas.com\\n- Rens.Feenstra@sas.com\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"inTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"outTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"textCol\": [],\n\t\t\"createPercentUsed\": true,\n\t\t\"maxCharsAllowed\": 240,\n\t\t\"createUserMentions\": true,\n\t\t\"concatAtSigns\": true,\n\t\t\"singleAtSigns\": true,\n\t\t\"createAtOccurences\": true,\n\t\t\"numOfAtOccurences\": 5,\n\t\t\"numOfAtOutputs\": 25,\n\t\t\"createHashtags\": true,\n\t\t\"concatHashtags\": true,\n\t\t\"singleHashtags\": true,\n\t\t\"createHTOccurences\": true,\n\t\t\"numOfHTOccurences\": 5,\n\t\t\"numOfHTOutputs\": 25,\n\t\t\"createLinks\": true,\n\t\t\"concatLinks\": true,\n\t\t\"singleLinks\": true,\n\t\t\"createLKOccurences\": true,\n\t\t\"numOfLKOccurences\": 5,\n\t\t\"numOfLKOutputs\": 25,\n\t\t\"extractCustomRegEx\": false,\n\t\t\"prxPattern\": \"\",\n\t\t\"minDocCnt\": 10,\n\t\t\"createCustomRegExGraphics\": true,\n\t\t\"createSnippetTable\": false,\n\t\t\"snipplet_window\": 10,\n\t\t\"outTableRexExContext\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"regExTargetCheck\": false,\n\t\t\"regExTarget\": [],\n\t\t\"minTgMean\": 7,\n\t\t\"maxTgMean\": 3,\n\t\t\"getLinkMetadata\": false,\n\t\t\"allowUnverifiedRequests\": false,\n\t\t\"urlLimiter\": 10,\n\t\t\"useTextAnalytics\": false,\n\t\t\"howLanguage\": {\n\t\t\t\"value\": \"1\",\n\t\t\t\"label\": \"Yes\"\n\t\t},\n\t\t\"userSpecifiedLanguage\": null,\n\t\t\"createLanguagePlot\": true,\n\t\t\"profileText\": false,\n\t\t\"compareReferenceCorpus\": false,\n\t\t\"createProfileTextGraphs\": true,\n\t\t\"createNumSentences\": false,\n\t\t\"createMaxTokenSentence\": false,\n\t\t\"detectSentiment\": false,\n\t\t\"createSentimentPlot\": true,\n\t\t\"createPredefinedConcepts\": false,\n\t\t\"conceptList\": [\n\t\t\t{\n\t\t\t\t\"value\": \"nlpDate\",\n\t\t\t\t\"label\": \"Date\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpMeasure\",\n\t\t\t\t\"label\": \"Measure\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpMoney\",\n\t\t\t\t\"label\": \"Money\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpNounGroup\",\n\t\t\t\t\"label\": \"Noun Group\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpOrganization\",\n\t\t\t\t\"label\": \"Organization\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpPercent\",\n\t\t\t\t\"label\": \"Percent\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpPerson\",\n\t\t\t\t\"label\": \"Person\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpPlace\",\n\t\t\t\t\"label\": \"Place\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpTime\",\n\t\t\t\t\"label\": \"Time\"\n\t\t\t}\n\t\t],\n\t\t\"createPreConceptPlot\": true,\n\t\t\"createConcatedPreConcepts\": false,\n\t\t\"singlePreConcepts\": false,\n\t\t\"useCustomConcepts\": false,\n\t\t\"custConInTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"compiledCustomConcepts\": false,\n\t\t\"customConInTable\": [],\n\t\t\"createCustomConceptPlot\": true,\n\t\t\"createConcatedCustomConcepts\": false,\n\t\t\"singleCustomConcepts\": false,\n\t\t\"createTopics\": false,\n\t\t\"useBestPractise\": true,\n\t\t\"posTagging\": true,\n\t\t\"extractNounGroups\": true,\n\t\t\"extractEntities\": true,\n\t\t\"stemTerms\": true,\n\t\t\"minOccKeep\": 10,\n\t\t\"cellWeight\": true,\n\t\t\"termWeight\": {\n\t\t\t\"value\": \"entropy\",\n\t\t\t\"label\": \"Entropy\"\n\t\t},\n\t\t\"useStopWords\": true,\n\t\t\"normProjects\": {\n\t\t\t\"value\": \"all\",\n\t\t\t\"label\": \"Both\"\n\t\t},\n\t\t\"numTopics\": {\n\t\t\t\"value\": \"1\",\n\t\t\t\"label\": \"Recommend number of topics\"\n\t\t},\n\t\t\"numTopicsK\": 25,\n\t\t\"numTopicsMaxK\": 25,\n\t\t\"resolutionLevel\": {\n\t\t\t\"value\": \"high\",\n\t\t\t\"label\": \"High\"\n\t\t},\n\t\t\"rotationType\": {\n\t\t\t\"value\": \"varimax\",\n\t\t\t\"label\": \"Uncorrelated Topics (Varimax)\"\n\t\t},\n\t\t\"numLabels\": 5,\n\t\t\"selectEntities\": false,\n\t\t\"defaultEntityPrio\": 0,\n\t\t\"hasCustomPrio\": false,\n\t\t\"createScreePlotSVD\": true,\n\t\t\"createBoolRules\": false,\n\t\t\"useTopicCreationTbD\": false,\n\t\t\"boolRuleTarget\": [],\n\t\t\"boolRuleTargetType\": {\n\t\t\t\"value\": \"Binary\",\n\t\t\t\"label\": \"Binary\"\n\t\t},\n\t\t\"gPosBR\": 10,\n\t\t\"mPosBR\": 10,\n\t\t\"gNegBR\": 10,\n\t\t\"mNegBR\": 10,\n\t\t\"minSupportsBR\": 10,\n\t\t\"maxCandidatesBR\": 10,\n\t\t\"maxTriesInBR\": 10,\n\t\t\"maxTriesOutBR\": 10\n\t}\n}","templates":{"SAS":"%macro _etm_create_base_metadata;\n\t* Count different metadata contained in the text;\n\t* And concatenating user mentions, hashtags and links;\n\tdata &outTable.;\n\t\tset &inTable.;\n\t\n\t\t%if &concatAtSigns. or &concatHashtags. or &concatLinks. or &useTextAnalytics. %then %do;\n\t\t\tlength _etm_ID 8.;\n\t\t\tlabel _etm_ID = 'Unqiue Document ID';\n\t\t\t\n\t\t\t_etm_ID = _N_;\n\t\t%end;\n\t\n\t\tlength _etm_N_FullStop _etm_N_Quest _etm_N_Exclam \n\t\t\t_etm_wrd_cnt _etm_chrctr_cnt _etm_i 8.;\n\n\t\t%if &createPercentUsed. %then %do;\n\t\t\tlength _etm_prcntUsd 8.;\n\t\t\tlabel _etm_prcntUsd = 'Percentage used of the maximum allowed characters';\n\t\t%end;\n\n\t\t%if &createUserMentions. %then %do;\n\t\t\tlength _etm_N_AtSigns 8.;\n\t\t\tlabel _etm_at_term = 'All User mentions in the text concatenated';\n\t\t\t_etm_N_AtSigns = count(&textCol_1_name_base.,'@');\n\t\t%end;\n\t\t%if &createHashtags. %then %do;\n\t\t\tlength _etm_N_HashTags 8.;\n\t\t\tlabel _etm_hshtg_term = 'All Hashtags in the text concatenated';\n\t\t\t_etm_N_HashTags = count(&textCol_1_name_base.,'#');\n\t\t%end;\n\t\t%if &createLinks. %then %do;\n\t\t\tlength _etm_N_Links  8.;\n\t\t\tlabel _etm_lnks_term = 'All links in the text concatenated';\n\t\t\t_etm_N_Links = count(&textCol_1_name_base.,'http');\n\t\t%end;\n\t\n\t\tlength _etm_tmp_at_term _etm_tmp_hshtg_term _etm_tmp_lnks_term \n\t\t\t_etm_at_term _etm_hshtg_term _etm_lnks_term $&textCol_1_rawlength.;\n\t\n\t\tlabel _etm_N_FullStop = 'Number of Periods in the Text'\n\t\t\t_etm_N_Quest = 'Number of Question Marks in the Text'\n\t\t\t_etm_N_Exclam = 'Number of Exclamations Points in the Text'\n\t\t\t_etm_N_AtSigns = 'Number of At Signs in the Text'\n\t\t\t_etm_N_HashTags = 'Number of Hashtags in the Text'\n\t\t\t_etm_N_Links = 'Number of Links in the Text'\n\t\t\t_etm_wrd_cnt = 'Number of Words in a Text'\n\t\t\t_etm_chrctr_cnt = 'Number of Characters in a Text';\n\t\n\t\t_etm_N_FullStop = count(&textCol_1_name_base.,'.');\n\t\t_etm_N_Quest = count(&textCol_1_name_base.,'?');\n\t\t_etm_N_Exclam = count(&textCol_1_name_base.,'!');\n\t\t_etm_wrd_cnt = countw(strip(&textCol_1_name_base.), ' ');\n\t\t_etm_chrctr_cnt = length(&textCol_1_name_base.);\n\t\n\t\t%if &createPercentUsed. %then %do;\n\t\t\t_etm_prcntUsd = _etm_chrctr_cnt / &maxCharsAllowed.;\n\t\t%end;\n\t\n\t\t* Create concataned Values;\n\t\t%if &concatAtSigns. or &concatHashtags. or &concatLinks. %then %do;\n\t\t\tlength _etm_tmp_at_term _etm_tmp_hshtg_term _etm_tmp_lnks_term $&textCol_1_rawlength.;\n\n\t\t\tif _etm_N_AtSigns > 0 or _etm_N_HashTags > 0 or _etm_N_Links > 0 then do;\n\t\t\t\t_etm_i = 1;\n\t\t\t\tdo while(_etm_i <= _etm_wrd_cnt);\n\t\n\t\t\t\t\t* Search for User mentions;\n\t\t\t\t\t%if &concatAtSigns. %then %do;\n\t\t\t\t\t\tlength _etm_at_term $&textCol_1_rawlength.;\n\t\t\t\t\t\tlabel _etm_at_term = 'Concatenated List of all User Mentions in the Text';\t\t\t\t\t\t\n\n\t\t\t\t\t\tif _etm_N_AtSigns > 0 then do;\n\t\t\t\t\t\t\t_etm_tmp_at_term = scan(strip(&textCol_1_name_base.), _etm_i);\n\t\t\t\t\t\t\tif substr(_etm_tmp_at_term, 1, 1) = '@' then do;\n\t\t\t\t\t\t\t\t_etm_tmp_at_term = lowcase(strip(_etm_tmp_at_term));\n\t\t\t\t\t\t\t\t_etm_at_term = strip(_etm_at_term) || ' ' || substr(_etm_tmp_at_term, 2);\n\t\t\t\t\t\t\tend;\n\t\t\t\t\t\tend;\n\t\t\t\t\t%end;\n\n\t\t\t\t\t* Search for Hashtags;\n\t\t\t\t\t%if &concatHashtags. %then %do;\n\t\t\t\t\t\tlength _etm_hshtg_term $&textCol_1_rawlength.;\n\t\t\t\t\t\tlabel _etm_hshtg_term = 'Concatenated List of all Hashtags in the Text';\n\n\t\t\t\t\t\tif _etm_N_HashTags > 0 then do;\n\t\t\t\t\t\t\t_etm_tmp_hshtg_term = scan(strip(&textCol_1_name_base.), _etm_i);\n\t\t\t\t\t\t\tif substr(_etm_tmp_hshtg_term, 1, 1) = '#' then do;\n\t\t\t\t\t\t\t\t_etm_tmp_hshtg_term = lowcase(strip(_etm_tmp_hshtg_term));\n\t\t\t\t\t\t\t\t_etm_hshtg_term = strip(_etm_hshtg_term) || ' ' || substr(_etm_tmp_hshtg_term, 2);\n\t\t\t\t\t\t\tend;\n\t\t\t\t\t\tend;\n\t\t\t\t\t%end;\n\t\n\t\t\t\t\t* Search for Links;\n\t\t\t\t\t%if &concatLinks. %then %do;\n\t\t\t\t\t\tlength _etm_lnks_term $&textCol_1_rawlength.;\n\t\t\t\t\t\tlabel _etm_lnks_term = 'Concatenated List of all Links in the Text';\n\n\t\t\t\t\t\tif _etm_N_Links > 0 then do;\n\t\t\t\t\t\t\t_etm_tmp_lnks_term = scan(strip(&textCol_1_name_base.), _etm_i, ' ');\n\t\t\t\t\t\t\tif substr(_etm_tmp_lnks_term, 1, 4) = 'http' then do;\n\t\t\t\t\t\t\t\t_etm_lnks_term = strip(_etm_lnks_term) || ' ' || strip(_etm_tmp_lnks_term);\n\t\t\t\t\t\t\tend;\n\t\t\t\t\t\tend;\n\t\t\t\t\t%end;\n\t\n\t\t\t\t\t_etm_i + 1;\n\t\t\t\tend;\n\t\t\tend;\n\n\t\t\tdrop _etm_i _etm_tmp_at_term _etm_tmp_hshtg_term _etm_tmp_lnks_term;\n\t\t%end;\n\trun;\n%mend _etm_create_base_metadata;\n\n%_etm_create_base_metadata;\n\n* Remove the macro;\nproc catalog cat=work.sasmacr;\n\tdelete _etm_create_base_metadata.macro;\nrun;\n\n* Check if the users wants the concatenated values as seperated columns;\n%if &singleAtSigns. or &singleHashtags. or &singleLinks. %then %do;\n\t* Get the max number of outputs;\n\tproc sql noprint;\n\t\tselect max(_etm_N_AtSigns) into :_etm_max_AtSign\n\t\t\t\tfrom &outTable.;\n\t\n\t\tselect max(_etm_N_HashTags) into :_etm_max_HashTags\n\t\t\t\tfrom &outTable.;\n\t\n\t\tselect max(_etm_N_Links) into :_etm_max_Links\n\t\t\t\tfrom &outTable.;\n\trun;\n\n\t%macro _etm_create_individual_cols;\n\t\tdata &outTable.;\n\t\t\tset &outTable.;\n\n\t\t\t* Separated Columns for User Mentions;\n\t\t\t%if &singleAtSigns. %then %do;\n\t\t\t\t%do i=1 %to &_etm_max_AtSign.;\n\t\t\t\t\tlength _etm_AtSign_&i. $&textCol_1_rawlength.;\n\t\t\t\t\tlabel _etm_AtSign_&i. = \"&i.. user mention in the text\";\n\t\t\t\t\t_etm_AtSign_&i. = scan(_etm_at_term, &i.);\n\t\t\t\t%end;\n\t\t\t%end;\n\n\t\t\t* Separated Columns for Hashtags;\n\t\t\t%if &singleHashtags. %then %do;\n\t\t\t\t%do i=1 %to &_etm_max_HashTags.;\n\t\t\t\t\tlength _etm_HashTags_&i. $&textCol_1_rawlength.;\n\t\t\t\t\tlabel _etm_HashTags_&i. = \"&i.. hashtag in the text\";\n\t\t\t\t\t_etm_HashTags_&i. = scan(_etm_hshtg_term, &i.);\n\t\t\t\t%end;\n\t\t\t%end;\n\n\t\t\t* Separated Columns for User Links;\n\t\t\t%if &singleLinks. %then %do;\n\t\t\t\t%do i=1 %to &_etm_max_Links.;\n\t\t\t\t\tlength _etm_lnks_&i. $&textCol_1_rawlength.;\n\t\t\t\t\tlabel _etm_lnks_&i. = \"&i.. link in the text\";\n\t\t\t\t\t_etm_lnks_&i. = scan(_etm_lnks_term, &i., ' ');\n\t\t\t\t%end;\n\t\t\t%end;\n\t\trun;\n\t%mend _etm_create_individual_cols;\n\n\t%_etm_create_individual_cols;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t   delete _etm_create_individual_cols.macro;\n\trun;\n\n\t* Remove macro variables, that where created in the step;\n\t%symdel _etm_max_AtSign _etm_max_HashTags _etm_max_Links;\n%end;\n\n\n* Check if the users wants Co-Occurences to be added;\n%if &createAtOccurences. or &createHTOccurences. or &createLKOccurences. %then %do;\n\t* Add a binary field on Co-Occurence 0 = No and 1 = Yes;\n\t%macro _etm_cooccurence;\n\t\t* Create a table containing a row per value and id;\n\t\tdata %if &createAtOccurences. %then work._etm_all_mentions(keep=_etm_ID _etm_tmp_at_term);\n\t\t\t%if &createHTOccurences. %then work._etm_all_hashtags(keep=_etm_ID _etm_tmp_hshtg_term);\n\t\t\t%if &createLKOccurences. %then work._etm_all_links(keep=_etm_ID _etm_tmp_lnks_term);\n\t\t\t;\n\t\t\n\t\t\tlength %if &createAtOccurences. %then _etm_tmp_at_term;\n\t\t\t\t%if &createHTOccurences. %then _etm_tmp_hshtg_term;\n\t\t\t\t%if &createLKOccurences. %then _etm_tmp_lnks_term;\n\t\t\t\t $&textCol_1_rawlength.;\n\n\t\t\tset &outTable.;\n\t\t\n\t\t\t* User Mentions;\n\t\t\t%if &createAtOccurences. %then %do;\n\t\t\t\t_etm_i = 1;\n\t\t\t\tif _etm_N_AtSigns > 0 then do;\n\t\t\t\t\tdo until(_etm_i <= _etm_N_AtSigns);\n\t\t\t\t\t\t_etm_tmp_at_term = scan(_etm_at_term, _etm_i);\n\t\t\t\t\t\toutput work._etm_all_mentions;\n\t\t\t\t\tend;\n\t\t\t\tend;\n\t\t\t%end;\n\t\t\n\t\t\t* HashTags;\n\t\t\t%if &createHTOccurences %then %do;\n\t\t\t\t_etm_i = 1;\n\t\t\t\tif _etm_N_HashTags > 0 then do;\n\t\t\t\t\tdo until(_etm_i <= _etm_N_HashTags);\n\t\t\t\t\t\t_etm_tmp_hshtg_term = scan(_etm_hshtg_term, _etm_i);\n\t\t\t\t\t\toutput work._etm_all_hashtags;\n\t\t\t\t\tend;\n\t\t\t\tend;\n\t\t\t%end;\n\t\t\n\t\t\t* Links;\n\t\t\t%if &createLKOccurences. %then %do;\n\t\t\t\t_etm_i = 1;\n\t\t\t\tif _etm_N_Links > 0 then do;\n\t\t\t\t\tdo until(_etm_i <= _etm_N_Links);\n\t\t\t\t\t\t_etm_tmp_lnks_term = scan(_etm_lnks_term, _etm_i, ' ');\n\t\t\t\t\t\toutput work._etm_all_links;\n\t\t\t\t\tend;\n\t\t\t\tend;\n\t\t\t%end;\n\t\trun;\n\t\t\n\t\t* Create a count per mention, hashtag and link;\n\t\t\tproc sql noprint;\n\t\t%if &createAtOccurences. %then %do;\n\t\t\tproc sql noprint;\n\t\t\t\tcreate table work._etm_all_mentions_grp as\n\t\t\t\t\tselect count(*) as count_texts, _etm_tmp_at_term\n\t\t\t\t\t\tfrom work._etm_all_mentions\n\t\t\t\t\t\t\tgroup by _etm_tmp_at_term\n\t\t\t\t\t\t\t\thaving count_texts > &numOfAtOccurences.\n\t\t\t\t\t\t\t\t\torder by count_texts desc;\n\t\t\trun;\n\n\t\t    proc sql noprint;\n\t\t        select _etm_tmp_at_term into :_etm_tmp_at_term separated by '|'\n\t\t        \tfrom work._etm_all_mentions_grp(obs=&numOfAtOutputs.);\n\t\t    run;\n\t\t\n\t\t    data &outTable.;\n\t\t        set &outTable.;\n\t\t        %do i= 1 %to &sqlobs.;\n\t\t             _etm_cooc_At_&i=(strip(_etm_at_term) eq \"%scan(&_etm_tmp_at_term.,&i.,'|')\");\n\t\t             Label _etm_cooc_At_&i.=\"Co-Occurence At_&i.: %scan(&_etm_tmp_at_term.,&i.,'|')\";\n\t\t        %end;\n\t\t    run;\n\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_all_mentions _etm_all_mentions_grp;\n\t\t\trun;\n\t\t%end;\n\n\t\t%if &createHTOccurences. %then %do;\n\t\t\tproc sql noprint;\n\t\t\t\tcreate table work._etm_all_hashtags_grp as\n\t\t\t\t\tselect count(*) as count_texts, _etm_tmp_hshtg_term\n\t\t\t\t\t\tfrom work._etm_all_hashtags\n\t\t\t\t\t\t\tgroup by _etm_tmp_hshtg_term\n\t\t\t\t\t\t\t\thaving count_texts > &numOfHTOccurences.\n\t\t\t\t\t\t\t\t\torder by count_texts desc;\n\t\t\trun;\n\n\t\t    proc sql noprint;\n\t\t        select _etm_tmp_hshtg_term into :_etm_tmp_hshtg_term separated by '|'\n\t\t        \tfrom work._etm_all_hashtags_grp(obs=&numOfHTOutputs.);\n\t\t    run;\n\t\t\n\t\t    data &outTable.;\n\t\t        set &outTable.;\n\t\t        %do i= 1 %to &sqlobs.;\n\t\t             _etm_cooc_HashTag_&i=(strip(_etm_hshtg_term) eq \"%scan(&_etm_tmp_hshtg_term.,&i.,'|')\");\n\t\t             Label _etm_cooc_HashTag_&i.=\"Co-Occurence HashTag_&i.: %scan(&_etm_tmp_hshtg_term.,&i.,'|')\";\n\t\t        %end;\n\t\t    run;\n\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_all_hashtags _etm_all_hashtags_grp;\n\t\t\trun;\n\t\t%end;\n\t\t%if &createLKOccurences. %then %do;\n\t\t\tproc sql noprint;\n\t\t\t\tcreate table work._etm_all_links_grp as\n\t\t\t\t\tselect count(*) as count_texts, _etm_tmp_lnks_term\n\t\t\t\t\t\tfrom work._etm_all_links\n\t\t\t\t\t\t\tgroup by _etm_tmp_lnks_term\n\t\t\t\t\t\t\t\thaving count_texts > &numOfLKOccurences.\n\t\t\t\t\t\t\t\t\torder by count_texts desc;\n\t\t\trun;\n\n\t\t    proc sql noprint;\n\t\t        select _etm_tmp_lnks_term into :_etm_tmp_lnks_term separated by '|'\n\t\t        \tfrom work._etm_all_links_grp(obs=&numOfLKOutputs.);\n\t\t    run;\n\t\t\n\t\t    data &outTable.;\n\t\t        set &outTable.;\n\t\t        %do i= 1 %to &sqlobs.;\n\t\t             _etm_cooc_Link_&i=(strip(_etm_lnks_term) eq \"%scan(&_etm_tmp_lnks_term.,&i.,'|')\");\n\t\t             Label _etm_cooc_Link_&i.=\"Co-Occurence Link_&i.: %scan(&_etm_tmp_lnks_term.,&i.,'|')\";\n\t\t        %end;\n\t\t    run;\n\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_all_links _etm_all_links_grp;\n\t\t\trun;\n\t\t%end;\n\t\n\t%mend _etm_cooccurence;\n\n\t%_etm_cooccurence;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t   delete _etm_cooccurence.macro;\n\trun;\n%end;\n\n* Extract a user specified RegEx Pattern as additional features;\n%if &extractCustomRegEx. %then %do;\n\n    %macro _etm_regex_extraction;\n        %let _etm_len_snip=%sysevalf(&textCol_1_rawlength.+2*&snipplet_window.);\n        \n        %if &regExTargetCheck. %then %do;\n            %let minTgMean = %sysevalf(&minTgMean. / 10);\n            %let maxTgMean = %sysevalf(&maxTgMean. / 10);\n        %end;\n\n        data work._etm_regex_trans(drop=start length stop REGEX len pos);\n            length _etm_occurance _etm_occurance_lc $&textCol_1_rawlength.. _etm_snipplet $&_etm_len_snip..;\n            label _etm_occurance = \"Value extracted by the RegEx Pattern: &prxPattern.\"\n                _etm_occurance_lc = \"Value extracted by the RegEx Pattern: &prxPattern.\"\n                _etm_snipplet = \"Added &snipplet_window. charachters around the found RegEx pattern to provide context\";\n        \n            if _n_ eq 1 then do;\n                REGEX=prxparse(\"&prxPattern.\");\n                if REGEX < 1 then put 'ERROR: Your specified RegEx Pattern was invalid, please check it!';\n            end;\n        \n            set &outTable.(keep=&textCol_1_name_base. _etm_ID %if &regExTargetCheck. %then %do; &regExTarget_1_name_base. %end;);\n        \n            start = 1;\n            _etm_snipplet = '';\n            length = &textCol_1_rawlength.;\n            stop = length;\n            len = stop - start + 1;\n\n            call prxnext(REGEX, start, stop, &textCol_1_name_base., pos, len);\n        \n            do while (pos gt 0);\n                _etm_occurance=ksubstr(&textCol_1_name_base., pos, len);\n                _etm_occurance_lc=lowcase(_etm_occurance);\n                _etm_snipplet=ksubstr(&textCol_1_name_base.,\n                    Max(1, pos - &snipplet_window.),\n                    Min(len + %sysevalf(2 * &snipplet_window.), &snipplet_window. + length - pos + 1)\n                );\n        \n                output;\n                call prxnext(REGEX, start, stop, &textCol_1_name_base., pos, len);\n            end;\n        \n            if _etm_occurance eq '' then output;\n        \n            retain REGEX;\n        run;\n\n        %if &createSnippetTable. %then %do;\n            data &outTableRexExContext.(drop=_etm_occurance_lc);\n                set work._etm_regex_trans(where=(strip(_etm_occurance) ne ''));\n            run;\n        %end;\n        \n        proc sql;\n            create table work._etm_occurance_cnt as\n                select  _etm_occurance_lc as _etm_occurance, count(distinct _etm_ID) as _etm_doc_cnt label = 'Number of documents containing each term extracted by the RegEx Pattern'\n                    %if &regExTargetCheck. %then %do;\n                        , mean(&regExTarget_1_name_base.) as _etm_&regExTarget_1_name_base._Mean\n                    %end;\n                    from work._etm_regex_trans\n                        group by _etm_occurance_lc\n                            order by\n                                %if &regExTargetCheck. %then %do;\n                                    _etm_&regExTarget_1_name_base._Mean descending,\n                                %end;\n                                _etm_doc_cnt descending;\n        quit;\n        \n\t\t%if &createCustomRegExGraphics %then %do;\n\t\t\tproc print data=work._etm_occurance_cnt;\n\t\t\t\tTitle \"Lowcase Pattern Matches in Column &textCol_1_name_base.\";\n\t\t\t\tFootnote \"RegEx Pattern: &prxPattern.\";\n\t\t\trun;\n\t\t\ttitle;\n\t\t\tfootnote;\n\t\t%end;\n\n        proc sql noprint;\n                select _etm_occurance into : Terms separated by ''\n                    from work._etm_occurance_cnt(where=(_etm_doc_cnt ge &MinDocCnt.\n                        and strip(_etm_occurance) ne ''\n                        %if &regExTargetCheck. %then %do;\n                            and (_etm_&regExTarget_1_name_base._mean ge &MinTgMean.\n                            or _etm_&regExTarget_1_name_base._mean le &MaxTgMean. )\n                        %end;\n                    ));\n        quit;\n\n        ods noproctitle;\n\n        %if &sqlobs. gt 0 %then %do;\n            data &outTable.(rename=(_etm_prx=_etm_prx_0));\n                set &outTable.;\n        \n                %do i= 1 %to &sqlobs.;\n                    _etm_prx_&i.=(find(&textCol_1_name_base.,\"%scan(&terms., &i., '')\", 'i') gt 1);\n                    label _etm_prx_&i.=\"RegEx Pattern Term &i.: %scan(&terms., &i., '')\";\n                %end;\n        \n                _etm_prx=(sum(of _etm_prx_:) gt 0);\n                Label _etm_prx=\"RegEx Pattern Term All: &prxPattern.\";\n            run;\n\n\t\t\t%if &createCustomRegExGraphics %then %do;\n\t\t\t\tproc freq data=&outTable.;\n\t\t\t\t\tTables %if &regExTargetCheck. ne %then %do; &regExTarget_1_name_base. %end; _etm_prx_:;\n\t\t\t\t\tTitle \"Feature Statistics\";\n\t\t\t\t\t%if &regExTargetCheck. %then %do;\n\t\t\t\t\t\tFootnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt., MinTgMean=&MinTgMean., MaxTgMean=&MaxTgMean.\";\n\t\t\t\t\t%end;\n\t\t\t\t\t%else %do;\n\t\t\t\t\t\tFootnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt.\";\n\t\t\t\t\t%end;\n\t\t\t\trun;\n\t\t\t\ttitle;\n\t\t\t\tfootnote;\n\n\t\t\t\tproc summary data=&outTable. print stackods Mean;\n\t\t\t\t\tTitle \"Feature Mean\";\n\t\t\t\t\tFootnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt.\";\n\t\t\t\t\tvar _etm_prx_:;\n\t\t\t\trun;\n\t\t\t\ttitle;\n\t\t\t\tfootnote;\n\t\t\t%end;\n            \n            %if &regExTargetCheck. %then %do;\n                proc freq data=&outTable.;\n                    Tables &regExTarget_1_name_base.*_etm_prx_:;\n                    Title \"Feature Association with Target Variable &regExTarget_1_name_base.\";\n                    Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt., MinTgMean=&MinTgMean., MaxTgMean=&MaxTgMean.\";\n                run;\n\t\t\t\ttitle;\n\t\t\t\tfootnote;\n\n                proc summary data=&outTable. print stackods Mean;\n                    Title \"Feature Mean within Target Variable: &regExTarget_1_name_base.\";\n                    Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt., MinTgMean=&MinTgMean., MaxTgMean=&MaxTgMean.\";\n                    var _etm_prx_:;\n                    ways 0 1;\n                    class &regExTarget_1_name_base.;\n                run;\n\t\t\t\ttitle;\n\t\t\t\tfootnote;\n            %end;\n        %end;\n\n\t\tods;\n\n\t\t* Remove the datasets;\n\t\tproc datasets library=work nolist;\n\t\t\tdelete _etm_regex_trans _etm_occurance_cnt;\n\t\trun; quit;\n    %mend _etm_regex_extraction;\n\n    %_etm_regex_extraction;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t\tdelete _etm_regex_extraction.macro;\n\trun; quit;\n%end;\n\n* Get metadata from links;\n%if &getLinkMetadata. %then %do;\n\t* Create a table of all links;\n\tdata work._etm_links(keep=_etm_lnks);\n\t\tset &outTable.(where=(_etm_lnks_term ^= '') keep=_etm_lnks_term _etm_N_Links);\n\t\t_etm_i = 1;\n\t\tdo while(_etm_i <= _etm_N_Links);\n\t\t\t_etm_lnks = scan(_etm_lnks_term, _etm_i, ' ');\n\t\t\toutput;\n\t\t\t_etm_i + 1;\n\t\tend;\n\trun;\n\n\t* Only keep unique links to reduce querying;\n\tproc sql outobs=&urlLimiter.;\n\t\tcreate table work._etm_distinct_links as\n\t\t\tselect count(_etm_lnks) as c1, _etm_lnks\n\t\t\t\tfrom work._etm_links\n\t\t\t\t\twhere _etm_lnks not in (' ', 'http', 'https')\n\t\t\t\t\t\torder by c1;\n\trun;\n\n\t%let _etm_n_links = &sqlobs.;\n\n\t%macro _etm_py_link_meta;\n\t\t%do i = 1 %to &_etm_n_links. / 25;\n\t\t\t%let _etm_firstob = %eval(&i. * 25);\n\t\t\t%let _etm_obsCount = %eval(&_etm_firstob. + 25);\n\n\t\t\t%if &i. = 1 %then %do;\n\t\t\t\tdata work._etm_links;\n\t\t\t\t\tset work._etm_distinct_links(obs=25);\n\t\t\t\trun;\n\n\t\t\t\tproc python restart infile=pgm;\n\t\t\t\trun;\n\n\t\t\t\tdata work._etm_link_meta_all;\n\t\t\t\t\tset work._etm_link_meta;\n\t\t\t\trun;\n\t\t\t%end;\n\t\t\t%else %if &i. = &_etm_n_links. / 25 %then %do;\n\t\t\t\tdata work._etm_links;\n\t\t\t\t\tset work._etm_distinct_links(firstobs=&_etm_firstob. obs=&_etm_obsCount.);\n\t\t\t\trun;\n\n\t\t\t\tproc python restart infile=pgm;\n\t\t\t\trun;\n\n\t\t\t\tproc append base=work._etm_link_meta_all data=work._etm_link_meta;\n\t\t\t\trun;\n\t\t\t%end;\n\t\t\t%else %do;\n\t\t\t\tdata work._etm_links;\n\t\t\t\t\tset work._etm_distinct_links(firstobs=&_etm_firstob.);\n\t\t\t\trun;\n\n\t\t\t\tproc python restart infile=pgm;\n\t\t\t\trun;\n\n\t\t\t\tproc append base=work._etm_link_meta_all data=work._etm_link_meta;\n\t\t\t\trun;\n\t\t\t%end;\n\t\t%end;\n\n\t%mend _etm_py_link_meta;\n\n\tfilename pgm \"_etm_link_meta.py\";\n\n\tdata _null_;\n\t\tfile pgm;\n\t\t\n\t\tput \"import pandas as pd\";\n\t\tput \"import requests\";\n\t\tput \"from bs4 import BeautifulSoup\";\n\n\t\tif &allowUnverifiedRequests. then do;\n\t\t\tput \"from urllib3.exceptions import InsecureRequestWarning\";\n\t\t\tput \"requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\";\n\t\tend;\n\n\t\tput \" \";\n\t\tput \"# Get the unique link table from SAS\";\n\t\tput \"_etm_df = SAS.sd2df('work._etm_links')\";\n\t\tput \" \";\n\t\tput \"# Function to gather link information for each link\";\n\t\tput \"def get_link_metadata(row):\";\n\t\tput \"\ttry:\";\n\n\t\tif &allowUnverifiedRequests. then do;\n\t\t\tput \"\t\tr = requests.get(row['_etm_lnks'], verify=False)\";\n\t\tend;\n\t\telse do;\n\t\t\tput \"\t\tr = requests.get(row['_etm_lnks'])\";\n\t\tend;\n\n\t\tput \"\t\thtml = BeautifulSoup(r, 'html.parser')\";\n\t\tput \"\t\t_etm_status_code = r.status_code\";\n\t\tput \"\t\t_etm_title = html.find('meta', attrs={'property': 'og:title'})\";\n\t\tput \"\t\t_etm_description = html.find('meta', attrs={'property': 'og:description'})\";\n\t\tput \"\t\t_etm_url = html.find('meta', attrs={'property': 'og:url'})\";\n\t\tput \"\t\t_etm_site_name = html.find('meta', attrs={'property': 'og:site_name'})\";\n\t\tput \"\texcept:\";\n\t\tput \"\t\t_etm_status_code = 404\";\n\t\tput \"\t\t_etm_title = 'Not available'\";\n\t\tput \"\t\t_etm_description = 'Not available'\";\n\t\tput \"\t\t_etm_url = 'Not available'\";\n\t\tput \"\t\t_etm_site_name = 'Not available'\";\n\t\tput \"\treturn _etm_status_code, _etm_title, _etm_description, _etm_url, _etm_site_name\";\n\t\tput \" \";\n\t\tput \"# Get the information for each link\";\n\t\tput \"_etm_df_meta = _etm_df.apply(get_link_metadata, axis='columns', result_type='expand')\";\n\t\tput \"_etm_df_all = pd.concat([_etm_df, _etm_df_meta], axis='columns')\";\n\t\tput \"_etm_df_all.rename(columns = {0:'_etm_status_code', 1:'_etm_title', 2:'_etm_description', 3:'_etm_url', 4:'_etm_site_name'}, inplace = True)\";\n\t\tput \" \";\n\t\tput \"# Return the information to SAS\";\n\t\tput \"SAS.df2sd(_etm_df_all, 'work._etm_link_meta')\";\n\trun;\n\t\n\t%_etm_py_link_meta;\n\n\tfilename pgm clear;\n\t\n\t* Add the link metadata back to table;\n\t%macro _etm_add_link_meta;\n\t\tproc sql noprint;\n\t\t\tselect max(_etm_N_Links) into :_etm_max_links\n\t\t\t\tfrom &outTable.;\n\t\trun;\n\t\t\n\t\tproc sql;\n\t\t\tcreate table work._etm_link_combined as\n\t\t\t\tselect a.*,\n\t\t\t\t\t%do i = 1 %to &_etm_max_links.;\n\t\t\t\t\t\t%if &i. > 1 %then %do;\n\t\t\t\t\t\t\t,\n\t\t\t\t\t\t%end;\n\t\t\t\t\t\tt&i.._etm_status_code as _etm_status_code_&i. label=\"HTTP Status Code of the &i.. Link\",\n\t\t\t\t\t\tt&i.._etm_title as _etm_title_&i. label=\"Website Title of the &i.. Link\",\n\t\t\t\t\t\tt&i.._etm_description as _etm_description_&i. label=\"Website Description of the &i.. Link\",\n\t\t\t\t\t\tt&i.._etm_url as _etm_url_&i. label=\"Website URL of the &i.. Link\",\n\t\t\t\t\t\tt&i.._etm_site_name as _etm_site_name_&i. label=\"Website Name of the &i.. Link\"\n\t\t\t\t\t%end;\n\t\t\t\t\t\tfrom &outTable. as a\n\t\t\t\t\t\t\t%do i = 1 %to &_etm_max_links.;\n\t\t\t\t\t\t\t\tleft join work._etm_link_meta as t&i.\n\t\t\t\t\t\t\t\t\ton a._etm_lnks_&i. = t&i.._etm_lnks\n\t\t\t\t\t\t\t%end;\n\t\t;run;\n\t\n\t\tdata &outTable.;\n\t\t\tset work._etm_link_combined;\n\t\trun;\n\t%mend _etm_add_link_meta;\n\t\n\t%_etm_add_link_meta;\n\n\t* Remove datasets;\n\tproc datasets library=work nolist;\n\t\tdelete _etm_links _etm_distinct_links _etm_link_meta _etm_link_meta_all _etm_link_combined;\n\trun;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t   delete _etm_py_link_meta.macro _etm_add_link_meta.macro;\n\trun;\n%end;\n\n* Add a language to the dataset;\n%if &useTextAnalytics. %then %do;\n\t* Sort the data by ID for results merge at the end;\n\tproc sort data=&outTable.;\n\t\tby _etm_ID;\n\trun;\n\n\tcas _etm_sess sessopts=(caslib=casuser);\n\tlibname _etm_cas cas caslib='casuser' datalimit=all;\n\n\t%macro _etm_add_language;\n\t\t* Automatic language detection;\n\t\t%if &howLanguage. %then %do;\n\t\t\t* Load the data into CAS;\n\t\t\tproc casutil session=_etm_sess;\n\t\t\t\tload data=&outTable. outcaslib='casuser'\n\t\t\t\tcasout='_etm_lang_detect' replace;\n\t\t\trun;\n\t\t\t\n\t\t\t* Detect the language of each text;\n\t\t\tproc cas;\n\t\t\t   session _etm_sess;\n\t\t\t\n\t\t\t\toutput log;\n\t\t\t\n\t\t\t\tloadactionset 'textManagement';\n\t\t\t\n\t\t\t\ttextManagement.identifyLanguage /\n\t\t\t\t\tcasOut={name='_etm_lang_detected', replace=True}\n\t\t\t\t\tdocId='_etm_ID'\n\t\t\t\t\ttable={name='_etm_lang_detect'}\n\t\t\t\t\ttext=\"&textCol_1_name_base.\";\n\t\t\trun; quit;\n\t\t\t\n\t\t\t* Pull the data down from CAS into SPRE;\n\t\t\tdata work._etm_lang(rename=(_language_=_etm_lang));\n\t\t\t\tset _etm_cas._etm_lang_detected(where=(_language_^=' '));\n\t\t\t\tlabel _language_ = 'Language of the text';\n\t\t\trun;\n\t\t\n\t\t\tproc sort data=work._etm_lang;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\t\t\t\n\t\t\t* Add the data to the output dataset;\n\t\t\tdata &outTable.;\n\t\t\t\tmerge &outTable. work._etm_lang;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\n\t\t\t* Create a bar chart of the detected languages;\n\t\t\t%if &createLanguagePlot. %then %do;\n\t\t\t\tods graphics / reset imagemap;\n\t\t\t\ttitle3 \"Distribution of the Detected Languages\";\n\t\t\t\tproc sgplot data = &outTable.;\n\t\t\t\t    vbar _etm_lang;\n\t\t\t\trun;\n\t\t\t\ttitle3;\n\t\t\t%end;\n\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_lang;\n\t\t\trun;\n\t\t%end;\n\t\t%else %do;\n\t\t\t* Language specified by the user;\n\t\t\tdata &outTable.;\n\t\t\t\tset &outTable.;\n\n\t\t\t\tlength _etm_lang $2.;\n\t\t\t\tlabel _etm_lang = 'Language of the text';\n\n\t\t\t\t_etm_lang = \"&userSpecifiedLanguage.\";\n\n\t\t\t\t* Handle the case of empty text;\n\t\t\t\tif &textCol_1_name_base. = '' then do;\n\t\t\t\t\t_etm_lang = ' ';\n\t\t\t\tend;\n\t\t\trun;\n\t\t%end;\n\t%mend _etm_add_language;\n\n\t%_etm_add_language;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t\tdelete _etm_add_language.macro;\n\trun; quit;\n%end;\n\n* Create translation of shorthand language to long formn language;\n* This dataset is used by actions that run for each language;\n%if &profileText. or &createTopics. or &createPredefinedConcepts. or &useCustomConcepts. or &createBoolRules. %then %do;\n\t* Long name of language for proc textmine;\n\tdata work._etm_lang_trans;\n\t\tinfile datalines delimiter=',';\n\t\tlength _etm_long_lang $15 _etm_short_lang $2;\n\t\tinput _etm_long_lang $ _etm_short_lang $;\n\t\t     \n\t\tdatalines;\nArabic, AR\nChinese, ZH\nCroatian, HR\nCzech, CS\nDanish, DA\nDutch, NL\nEnglish, EN\nFinnish, FI\nFrench, FR\nGerman, DE\nGreek, EL\nHebrew, IW\nHindi, HI\nHungarian, HU\nIndonesian, IN\nItalian, IT\nJapanese, JA\nKazakh, KK\nKorean, KO\nNorwegian, NO\nPersian, FA\nPolish, PL\nPortuguese, PT\nRomanian, RO\nRussian, RU\nSlovak, SK\nSlovene, SL\nSpanish, ES\nSwedish, SV\nTagalog, TL\nThai, TH\nTurkish, TR\nVietnamese, VI\n;\n\trun;\n%end;\n\n* Profile the text corpus;\n%if &profileText. %then %do;\n\tproc casutil session=_etm_sess;\n\t\tload data=&outTable. outcaslib='casuser'\n\t\tcasout='_etm_profile_text' replace;\n\trun;\n\t\n\t%macro _etm_profile_text;\n\t\t* Select all distinct languages in the dataset;\n\t\tproc sql noprint;\n\t\t\tselect distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n\t\t\t\tfrom &outTable.\n\t\t\t\t\twhere _etm_lang ne ' ';\n\t\trun;\n\n\t\t%do i=1 %to &_etm_lang_cnt.;\n\t\t\t* Create a separate dataset for each language;\n\t\t\tdata _etm_cas._etm_lang_&&_etm_lang&i.;\n\t\t\t\tset &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n\t\t\trun;\n\n\t\t\tdata _null_;\n\t\t\t\tset work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n\t\t\t\tcall symputx('_etm_long_lang', _etm_long_lang);\n\t\t\trun;\n\n\t\t\t*Run the text profiling;\n\t\t\tproc cas;\n\t\t\t\tsession _etm_sess;\n\t\t\t\t\t\t\n\t\t\t\toutput log;\n\t\t\t\n\t\t\t\tloadactionset \"textManagement\";\n\t\t\t\n\t\t\t\ttextManagement.profileText /\n\t\t\t\tcasOut = {name = '_etm_profile_text_out', replace = True}\n\t\n\t\t\t\t%if &compareReferenceCorpus. %then %do;\n\t\t\t\t\treferenceData = True\n\t\t\t\t%end;\n\t\n\t\t\t\tdocumentId = '_etm_ID'\n\t\t\t\tdocumentOut = {name = '_etm_document_out', replace = True}\n\t\t\t\tlanguage = \"&_etm_long_lang.\"\n\t\t\t\ttable = {name = '_etm_profile_text'}\n\t\t\t\ttext = \"&textCol_1_name_base.\";\n\t\t\trun; quit;\n\t\n\t\t\tods noproctitle;\n\n\t\t\t* Print the Results of the Profiling action to the Results;\n\t\t\ttitle3 \"Profile Text for the &_etm_long_lang. texts in the Corpus\";\n\t\t\tproc cas;\n\t\t\t\tsession _etm_sess;\n\t\n\t\t\t\ttable.fetch / table= {name = '_etm_profile_text_out'};\n\t\t\trun; quit;\n\t\t\ttitle3;\n\n\t\t\t* Print Word and Sentence Count Graphs;\n\t\t\t%if &createProfileTextGraphs. %then %do;\n\t\t\t\ttitle \"Sentences Count in Documents for &_etm_long_lang.\";\n\t\t\t\tproc sgplot data=_etm_cas._etm_document_out;\n\t\t\t\t\tvbar _num_sentences_;\n\t\t\t\t\tyaxis label='Number of Documents' grid;\n\t\t\t\t\txaxis label='Number of Sentences';\n\t\t\t\trun;\n\t\t\t\ttitle;\n\n\t\t\t\ttitle \"Word Count in Documents for &_etm_long_lang.\";\n\t\t\t\tproc sgplot data=&outTable.;\n\t\t\t\t\tvbar _etm_wrd_cnt;\n\t\t\t\t\tyaxis label='Number of Documents' grid;\n\t\t\t\t\txaxis label='Number of Words';\n\t\t\t\trun;\n\t\t\t\ttitle;\n\t\t\t%end;\n\n\t\t%end;\n\n\t\t* Add new features derived from the Profiling action;\n\t\t%if &createNumSentences. or &createMaxTokenSentence. %then %do;\n\t\t\tproc sql;\n\t\t\t\tcreate table work._etm_profile_text as\n\t\t\t\t\tselect _etm_ID\n\t\t\t\t\t\t%if &createNumSentences. %then %do;\n\t\t\t\t\t\t\t, _num_sentences_ as _etm_num_sentences label = 'Number of sentences in the Text'\n\t\t\t\t\t\t%end;\n\t\t\t\t\t\t%if &createMaxTokenSentence. %then %do;\n\t\t\t\t\t\t\t, _max_tokens_sentence_ as _etm_max_tokens_sentence label = 'Number of Tokens in the longest Sentence in the Text'\n\t\t\t\t\t\t%end;\n\t\t\t\t\t\tfrom _etm_cas._etm_document_out\n\t\t\t\t\t\t\torder by _etm_ID;\n\t\t\trun;\n\n\t\t\tdata &outTable.;\n\t\t\t\tmerge &outTable. work._etm_profile_text;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_profile_text;\n\t\t\trun; quit;\n\t\t%end;\n\n\t%mend _etm_profile_text;\n\t\n\t%_etm_profile_text;\n\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t\tdelete _etm_profile_text.macro;\n\trun; quit;\n%end;\n\n* Detect the sentiment of each text;\n%if &detectSentiment. %then %do;\n\t%macro _etm_by_lang;\n\t\t* Select all distinct languages in the dataset;\n\t\tproc sql noprint;\n\t\t\tselect distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n\t\t\t\tfrom &outTable.\n\t\t\t\t\twhere _etm_lang ne ' ';\n\t\trun;\n\t\n\t\t%do i=1 %to &_etm_lang_cnt.;\n\t\t\t* If text profiling is not selected, then the language split has to be created;\n\t\t\t%if not &profileText. %then %do;\n\t\t\t\t* Create a separate dataset for each language;\n\t\t\t\tdata _etm_cas._etm_lang_&&_etm_lang&i.;\n\t\t\t\t\tset &outTable.(where=(_etm_lang=\"&&&&_etm_lang&i.\"));\n\t\t\t\trun;\n\t\t\t%end;\n\n\t\t\tdata _null_;\n\t\t\t\tset work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n\t\t\t\tcall symputx('_etm_long_lang', _etm_long_lang);\n\t\t\trun;\n\t\n\t\t\t* Score the sentiment for each text;\n\t\t\tproc cas;\n\t\t\t \tsession _etm_sess;\n\t\t\t\n\t\t\t\toutput log;\n\t\t\t\n\t\t\t\tloadactionset \"sentimentAnalysis\";\n\t\t\t\n\t\t\t\taction sentimentAnalysis.applySent;\n\t\t\t\t\tparam\n\t\t\t\t\t\tdocId='_etm_ID'\n\t\t\t\t\t\ttext=\"&textCol_1_name_base.\"\n\t\t\t\t\t\tlanguage=\"&_etm_long_lang.\"\n\t\t\t\t\t\ttable={name=\"_etm_lang_&&_etm_lang&i.\"}\n\t\t\t\t\t\tcasOut={name=\"_etm_sent_&&_etm_lang&i.\", replace=True};\n\t\t\t\trun; \n\t\t\tquit;\n\n\t\t\t* Move the sentiment data from CAS to SPRE;\n\t\t\tdata work._etm_sent_&&_etm_lang&i.;\n\t\t\t\tlength _etm_sentiment $32. _etm_sentiment_score 8.;\n\t\t\t\tlabel _etm_sentiment = 'Sentiment of the text'\n\t\t\t\t\t_etm_sentiment_score = 'Score value for the sentiment of the text';\n\n\t\t\t\tset _etm_cas._etm_sent_&&_etm_lang&i.;\n\n\t\t\t\t_etm_sentiment = _sentiment_;\n\t\t\t\t_etm_sentiment_score = _score_;\n\n\t\t\t\tdrop _sentiment_ _score_;\n\t\t\trun;\n\n\t\t\tproc sort data=work._etm_sent_&&_etm_lang&i.;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\n\t\t\t* Add the sentiment and score to the data;\n\t\t\tdata &outTable.;\n\t\t\t\tmerge &outTable. work._etm_sent_&&_etm_lang&i.;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\t\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_sent_&&_etm_lang&i.;\n\t\t\trun; quit;\n\t\t%end;\n\n\t\t* Create a bar chart of the sentiment languages;\n\t\t%if &createSentimentPlot. %then %do;\n\t\t\tods graphics / reset imagemap;\n\t\t\ttitle3 \"Distribution of the Sentiment by Languages\";\n\t\t\tproc sgplot data = &outTable.;\n\t\t\t    vbar _etm_sentiment / group = _etm_lang groupdisplay=stack;\n\t\t\trun;\n\t\t\ttitle3;\n\t\t%end;\n\t%mend _etm_by_lang;\n\t\n\t%_etm_by_lang;\n\t\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t   delete _etm_by_lang.macro;\n\trun; quit;\n%end;\n\n* Apply the SAS Predefined Concepts to the data;\n%if &createPredefinedConcepts. and &conceptList_count. > 0 %then %do;\n\t%macro _etm_predefined_concepts;\n\t\t* Bring the user selected concepts in the format for a where clause;\n\t\tdata _null_;\n\t\t\t_etm_prcncpt_all = \"'\" || \"&conceptList_1.\" || \"'\"\n\t\t\t%do j = 1 %to &conceptList_count.;\n\t\t\t\t|| \",'\" || \"&&conceptList_&j.\" || \"'\"\n\t\t\t%end;\n\t\t\t;\n\t\t\tcall symputx('_etm_prcncpt_all', _etm_prcncpt_all);\n\t\trun;\n\n\t\t* Select all distinct languages in the dataset;\n\t\tproc sql noprint;\n\t\t\tselect distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n\t\t\t\tfrom &outTable.\n\t\t\t\t\twhere _etm_lang ne ' ';\n\t\trun;\n\n\t\t%do i=1 %to &_etm_lang_cnt.;\n\t\t\t* If text profiling and sentiment detection are not selected, then the language split has to be created;\n\t\t\t%if not &profileText. and not &detectSentiment. %then %do;\n\t\t\t\t* Create a separate dataset for each language;\n\t\t\t\tdata _etm_cas._etm_lang_&&_etm_lang&i.;\n\t\t\t\t\tset &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n\t\t\t\trun;\n\t\t\t%end;\n\n\t\t\tdata _null_;\n\t\t\t\tset work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n\t\t\t\tcall symputx('_etm_long_lang', _etm_long_lang);\n\t\t\trun;\n\n\t\t\t* Apply the SAS predefined concepts to the text;\n\t\t\tproc cas;\n\t\t\t\tsession _etm_sess;\n\t\t\t\n\t\t\t\toutput log;\n\t\t\t\n\t\t\t\tloadactionset 'textRuleDevelop';\n\t\t\t\tloadactionset 'textRuleScore';\n\t\t\t\n\t\t\t\taction compileConcept;\n\t\t\t\t\tparam\n\t\t\t\t\t\tcasOut = {name = '_etm_comp_Concepts', replace = True}\n\t\t\t\t\t\tenablePredefined = True\n\t\t\t\t\t\tlanguage = \"&_etm_long_lang.\";\n\t\t\t\trun;\n\t\t\t\n\t\t\t\taction applyConcept;\n\t\t\t\t\tparam\n\t\t\t\t\t\tcasOut = {name = \"_etm_concepts_&&_etm_lang&i.\", replace = True}\n\t\t\t\t\t\tlanguage = \"&_etm_long_lang.\"\n\t\t\t\t\t\tdocId = '_etm_ID'\n\t\t\t\t\t\tmodel = {name = '_etm_comp_Concepts'}\n\t\t\t\t\t\ttable = {name = \"_etm_lang_&&_etm_lang&i.\"}\n\t\t\t\t\t\ttext = \"&textCol_1_name_base.\";\n\t\t\t   run;\n\t\t\tquit;\n\t\t%end;\n\n\t\t* Append all concepts in one table;\n\t\tdata work._etm_all_concepts(drop=_start_ _end_ _canonical_form_ _path_);\n\t\t\tlength _etm_match_text $&textCol_1_rawlength. _etm_concept $15.;\n\t\t\tlabel _etm_match_text = 'The matched text for the concept'\n\t\t\t\t_etm_concept = 'The concept that was found in the text';\n\t\t\tset\n\t\t%do i=1 %to &_etm_lang_cnt.;\n\t\t\t_etm_cas._etm_concepts_&&_etm_lang&i.(where=(_concept_ in (&_etm_prcncpt_all.)))\n\t\t%end;\n\t\t\t;\n\t\t\t_etm_match_text = _match_text_;\n\t\t\t_etm_concept = _concept_;\n\t\t\tdrop _match_text_ _concept_;\n\t\trun;\n\n\t\t* Sort the data by the document ID to do by group processing;\n\t\tproc sort data=work._etm_all_concepts;\n\t\t\tby _etm_ID _etm_concept;\n\t\trun;\n\n\t\t* Generate the new features based on the predefined concepts;\n\t\tdata work._etm_all_concepts;\n\t\t\tset work._etm_all_concepts;\n\t\t\tby _etm_ID _etm_concept;\n\t\t\n\t\t\t* New Features from Concepts;\n\t\t\tlength _etm_total_concepts 8.;\n\t\t\tlabel _etm_total_concepts = 'Total Number of Concepts found in the Text';\n\n\t\t\t* Columns per Selected Predefined Concept;\n\t\t\t%do k=1 %to &conceptList_count.;\n\t\t\t\tlength _etm_&&conceptList_&k.._count 8.;\n\t\t\t\tlabel _etm_&&conceptList_&k.._count = \"Count for &&conceptList_&k. in the Text\";\n\t\t\t%end;\n\n\t\t\t%if &createConcatedPreConcepts. %then %do;\n\t\t\t\t%do l=1 %to &conceptList_count.;\n\t\t\t\t\tlength _etm_&&conceptList_&l.._cat $&textCol_1_rawlength.;\n\t\t\t\t\tlabel _etm_&&conceptList_&l.._cat = \"Concatenated List of all Matched Texts for the Concept _etm_&&conceptList_&l.._cat\";\n\t\t\t\t%end;\n\t\t\t%end;\n\n\t\t\tif first._etm_concept then do;\n\t\t\t\t%do m=1 %to &conceptList_count.;\n\t\t\t\t\t_etm_&&conceptList_&m.._count = 1;\n\n\t\t\t\t\t%if &createConcatedPreConcepts. %then %do;\n\t\t\t\t\t\t_etm_&&conceptList_&m.._cat = '';\n\t\t\t\t\t\tif _etm_concept = \"&&conceptList_&m.\" then do;\n\t\t\t\t\t\t\t_etm_&&conceptList_&m.._cat = _etm_match_text;\n\t\t\t\t\t\tend;\n\t\t\t\t\t%end;\n\t\t\t\t%end;\n\t\t\tend;\n\t\t\telse do;\n\t\t\t\t%do n=1 %to &conceptList_count.;\n\t\t\t\t\tif _etm_concept = \"&&conceptList_&n.\" then do;\n\t\t\t\t\t\t_etm_&&conceptList_&n.._count + 1;\n\n\t\t\t\t\t\t%if &createConcatedPreConcepts. %then %do;\n\t\t\t\t\t\t\t_etm_&&conceptList_&n.._cat = strip(_etm_&&conceptList_&n.._cat) || '||' || _etm_match_text;\n\t\t\t\t\t\t%end;\n\t\t\t\t\tend;\n\t\t\t\t%end;\n\t\t\tend;\n\n\t\t\tif first._etm_ID and last._etm_ID then do;\n\t\t\t\t_etm_total_concepts = 1;\n\t\t\t\toutput;\n\t\t\tend;\n\t\t\telse if first._etm_ID then do;\n\t\t\t\t_etm_total_concepts = 1;\n\t\t\tend;\n\t\t\telse if last._etm_ID then do;\n\t\t\t\t_etm_total_concepts + 1;\n\t\t\t\toutput;\n\t\t\tend;\n\t\t\telse do;\n\t\t\t\t_etm_total_concepts + 1;\n\t\t\tend;\n\n\t\t\tretain _etm_total_concepts\n\t\t\t%do o=1 %to &conceptList_count.;\n\t\t\t\t_etm_&&conceptList_&o.._count\n\t\t\t\t%if &createConcatedPreConcepts. %then %do;\n\t\t\t\t\t_etm_&&conceptList_&o.._cat\n\t\t\t\t%end;\n\t\t\t%end;\n\t\t\t;\n\t\trun;\n\n\t\tdata &outTable.;\n\t\t\tmerge &outTable. work._etm_all_concepts;\n\t\t\tby _etm_ID;\n\t\trun;\n\n\t\t* Create a bar chart of the extracted SAS Predefined Concepts;\n\t\t%if &createPreConceptPlot. %then %do;\n\t\t\tods graphics / reset imagemap;\n\t\t\ttitle3 \"Distribution of the Extracted SAS Predefined Concepts by Languages\";\n\t\t\tproc sgplot data = &outTable.;\n\t\t\t\tvbar _etm_concept / group=_etm_lang;\n\t\t\trun;\n\t\t\ttitle3;\n\t\t%end;\n\n\t\t* Remove datasets;\n\t\tproc datasets library=work nolist;\n\t\t\tdelete _etm_all_concepts;\n\t\trun; quit;\n\t%mend _etm_predefined_concepts;\n\n\t%_etm_predefined_concepts;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t\tdelete _etm_predefined_concepts.macro;\n\trun; quit;\n%end;\n\n%if &singlePreConcepts. %then %do;\n\t%macro _etm_create_single_precon;\n\t\t* Get the max number of concepts per Text;\n\t\tproc sql noprint;\n\t\t\t\t%do i=1 %to &conceptList_count.;\n\t\t\t\t\tselect max(_etm_&&conceptList_&i.._count) into :_etm_max_&&conceptList_&i.\n\t\t\t\t\t\tfrom &outTable.;\n\t\t\t\t%end;\n\t\trun;\n\n\t\t%do j=1 %to &conceptList_count.;\n\t\t\tdata &outTable.;\n\t\t\t\tset &outTable.;\n\t\t\t\t%do k=1 %to &conceptList_count.;\n\t\t\t\t\t%do m=1 %to &&&&_etm_max_&&conceptList_&k.;\n\t\t\t\t\t\tlength _etm_&&conceptList_&k.._&m. $&textCol_1_rawlength.;\n\t\t\t\t\t\tlabel _etm_&&conceptList_&k.._&m. = \"&m.. &&conceptList_&k. Concept in the Text\";\n\t\t\t\t\t\t_etm_&&conceptList_&k.._&m. = scan(_etm_&&conceptList_&k.._cat, &m., '||');\n\t\t\t\t\t%end;\n\t\t\t\t%end;\n\t\t\trun;\n\t\t%end;\n\n\t%mend _etm_create_single_precon;\n\n\t%_etm_create_single_precon;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t   delete _etm_create_single_precon.macro;\n\trun;\n%end;\n\n* Extract Custom Concepts from the Text;\n%if &useCustomConcepts. %then %do;\n    %macro addCustomConcepts;\n        * Load the data into CAS;\n        proc casutil session=_etm_sess;\n            load data=&custConInTable. outcaslib='casuser'\n            casout='_etm_custom_concept' replace;\n        run;\n\n        * Select all distinct languages in the dataset;\n\t\tproc sql noprint;\n\t\t\tselect distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n\t\t\t\tfrom &outTable.\n\t\t\t\t\twhere _etm_lang ne ' ';\n\t\trun;\n\n        %do i=1 %to &_etm_lang_cnt.;\n            * If the language split has to be created;\n            %if not &profileText. and not &detectSentiment. and not &createPredefinedConcepts. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n                run;\n            %end;\n\n            data _null_;\n\t\t\t\tset work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n\t\t\t\tcall symputx('_etm_long_lang', _etm_long_lang);\n\t\t\trun;\n\n            proc cas;\n\n                session _etm_sess;\n\n                output log;\n                \n                %if not &compiledCustomConcepts. and &i. eq 1 %then %do;\n                    loadactionset 'textRuleDevelop';\n\n                    action compileConcept;\n                        param\n                            casOut={name='_etm_custom_concept', replace=True} \n                            config=\"&customConInTable_1_name_base.\"\n                            table={name='_etm_custom_concept'};\n                        run;\n                %end;\n\n                loadactionset 'textRuleScore';\n\n                action applyConcept;\n                    param\n                        casOut = {name = \"_etm_cus_concepts_&&_etm_lang&i.\", replace = True}\n                        language = \"&_etm_long_lang.\"\n                        docId = '_etm_ID'\n                        model = {name = '_etm_custom_concept'}\n                        table = {name = \"_etm_lang_&&_etm_lang&i.\"}\n                        text = \"&textCol_1_name_base.\";\n                    run;\n            quit;\n        %end;\n\n        * Append all concepts in one table;\n        data work._etm_all_custom_concepts(drop=_start_ _end_ _canonical_form_ _path_);\n            length _etm_custom_match_text $&textCol_1_rawlength. _etm_custom_concept $256.;\n            label _etm_custom_match_text = 'The matched text for the concept'\n                _etm_custom_concept = 'The concept that was found in the text';\n            set\n        %do i=1 %to &_etm_lang_cnt.;\n            _etm_cas._etm_cus_concepts_&&_etm_lang&i.\n        %end;\n            ;\n            _etm_custom_match_text = _match_text_;\n            _etm_custom_concept = _concept_;\n            drop _match_text_ _concept_;\n        run;\n\n        * Sort the data by the document ID to do by group processing;\n        proc sort data=work._etm_all_custom_concepts;\n            by _etm_ID _etm_custom_concept;\n        run;\n\n        * Count the number of distinct custom concepts found in the data;\n        proc sql noprint;\n            select distinct _etm_custom_concept into :_etm_custom_concept_1-\n                from work._etm_all_custom_concepts;\n\n            select count(distinct _etm_custom_concept) into :_etm_custom_concept_cnt\n                from work._etm_all_custom_concepts;\n        run;\n\n        * Generate the new features based on the predefined concepts;\n\t\tdata work._etm_all_custom_concepts;\n\t\t\tset work._etm_all_custom_concepts;\n\t\t\tby _etm_ID _etm_custom_concept;\n\t\t\n\t\t\t* New Features from Concepts;\n\t\t\tlength _etm_total_custom_concepts 8.;\n\t\t\tlabel _etm_total_custom_concepts = 'Total Number of Custom Concepts found in the Text';\n\n\t\t\t* Columns per Selected Predefined Concept;\n\t\t\t%do k=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\tlength _etm_&&_etm_custom_concept_&k.._count 8.;\n\t\t\t\tlabel _etm_&&_etm_custom_concept_&k.._count = \"Count for &&_etm_custom_concept_&k. in the Text\";\n\t\t\t%end;\n\n\t\t\t%if &createConcatedCustomConcepts. %then %do;\n\t\t\t\t%do l=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\t\tlength _etm_&&_etm_custom_concept_&l.._cat $&textCol_1_rawlength.;\n\t\t\t\t\tlabel _etm_&&_etm_custom_concept_&l.._cat = \"Concatenated List of all Matched Texts for the Concept _etm_&&_etm_custom_concept_&l.._cat\";\n\t\t\t\t%end;\n\t\t\t%end;\n\n\t\t\tif first._etm_custom_concept then do;\n\t\t\t\t%do m=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\t\t_etm_&&_etm_custom_concept_&m.._count = 1;\n\n\t\t\t\t\t%if &createConcatedCustomConcepts. %then %do;\n\t\t\t\t\t\t_etm_&&_etm_custom_concept_&m.._cat = '';\n\t\t\t\t\t\tif _etm_custom_concept = \"&&_etm_custom_concept_&m.\" then do;\n\t\t\t\t\t\t\t_etm_&&_etm_custom_concept_&m.._cat = _etm_custom_match_text;\n\t\t\t\t\t\tend;\n\t\t\t\t\t%end;\n\t\t\t\t%end;\n\t\t\tend;\n\t\t\telse do;\n\t\t\t\t%do n=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\t\tif _etm_custom_concept = \"&&_etm_custom_concept_&n.\" then do;\n\t\t\t\t\t\t_etm_&&_etm_custom_concept_&n.._count + 1;\n\n\t\t\t\t\t\t%if &createConcatedCustomConcepts. %then %do;\n\t\t\t\t\t\t\t_etm_&&_etm_custom_concept_&n.._cat = strip(_etm_&&_etm_custom_concept_&n.._cat) || '||' || _etm_custom_match_text;\n\t\t\t\t\t\t%end;\n\t\t\t\t\tend;\n\t\t\t\t%end;\n\t\t\tend;\n\n\t\t\tif first._etm_ID and last._etm_ID then do;\n                _etm_total_custom_concepts = 1;\n\t\t\t\toutput;\n\t\t\tend;\n\t\t\telse if first._etm_ID then do;\n                _etm_total_custom_concepts = 1;\n\t\t\tend;\n\t\t\telse if last._etm_ID then do;\n                _etm_total_custom_concepts + 1;\n\t\t\t\toutput;\n\t\t\tend;\n\t\t\telse do;\n                _etm_total_custom_concepts + 1;\n\t\t\tend;\n\n\t\t\tretain _etm_total_custom_concepts\n\n\t\t\t%do o=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\t_etm_&&_etm_custom_concept_&o.._count\n\t\t\t\t%if &createConcatedCustomConcepts. %then %do;\n\t\t\t\t\t_etm_&&_etm_custom_concept_&o.._cat\n\t\t\t\t%end;\n\t\t\t%end;\n\t\t\t;\n\t\trun;\n\n\t\tdata &outTable.;\n\t\t\tmerge &outTable. work._etm_all_custom_concepts;\n\t\t\tby _etm_ID;\n\t\trun;\n\n        data &outTable.;\n\t\t\tmerge &outTable. work._etm_all_custom_concepts;\n\t\t\tby _etm_ID;\n\t\trun;\n\n\t\t* Create a bar chart of the extracted Custom Concepts;\n\t\t%if &createCustomConceptPlot. %then %do;\n\t\t\tods graphics / reset imagemap;\n\t\t\ttitle3 \"Distribution of the Extracted Custom Concepts by Languages\";\n\t\t\tproc sgplot data = &outTable.;\n\t\t\t\tvbar _etm_custom_concept / group=_etm_lang;\n\t\t\trun;\n\t\t\ttitle3;\n\t\t%end;\n    %mend addCustomConcepts;\n\n    %addCustomConcepts;\n\n    * Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t\tdelete addCustomConcepts.macro;\n\trun; quit;\n%end;\n\n* Create separated columns for the Custom Concepts;\n%if &singleCustomConcepts. %then %do;\n\t%macro _etm_create_single_custom_con;\n        * Count the number of distinct custom concepts found in the data;\n        proc sql noprint;\n            select distinct _etm_custom_concept into :_etm_custom_concept_1-\n                from work._etm_all_custom_concepts;\n\n            select count(distinct _etm_custom_concept) into :_etm_custom_concept_cnt\n                from work._etm_all_custom_concepts;\n        run;\n\n\t\t* Get the max number of concepts per Text;\n\t\tproc sql noprint;\n\t\t\t\t%do i=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\t\tselect max(_etm_&&_etm_custom_concept_&i.._count) into :_etm_max_&&_etm_custom_concept_&i.\n\t\t\t\t\t\tfrom &outTable.;\n\t\t\t\t%end;\n\t\trun;\n\n\t\t%do j=1 %to &_etm_custom_concept_cnt.;\n\t\t\tdata &outTable.;\n\t\t\t\tset &outTable.;\n\t\t\t\t%do k=1 %to &_etm_custom_concept_cnt.;\n\t\t\t\t\t%do m=1 %to &&&&_etm_max_&&_etm_custom_concept_&k.;\n\t\t\t\t\t\tlength _etm_&&_etm_custom_concept_&k.._&m. $&textCol_1_rawlength.;\n\t\t\t\t\t\tlabel _etm_&&_etm_custom_concept_&k.._&m. = \"&m.. &&_etm_custom_concept_&k. Concept in the Text\";\n\t\t\t\t\t\t_etm_&&_etm_custom_concept_&k.._&m. = scan(_etm_&&_etm_custom_concept_&k.._cat, &m., '||');\n\t\t\t\t\t%end;\n\t\t\t\t%end;\n\t\t\trun;\n\t\t%end;\n\t%mend _etm_create_single_custom_con;\n\n\t%_etm_create_single_custom_con;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t   delete _etm_create_single_custom_con.macro;\n\trun;\n%end;\n\n* Create Text Topics for each Language;\n%if &createTopics. %then %do;\n\t%macro _etm_topic_discovery;\n\n\t\t* Select all distinct languages in the dataset;\n\t\t* Filter languages that have more then 50 rows;\n\t\tproc sql noprint;\n\t\t\tcreate table work._etm_lang_grp as\n\t\t\tselect count(_etm_lang) as _etm_lang_cnt, _etm_lang\n\t\t\t\tfrom &outTable.\n\t\t\t\t\tgroup by _etm_lang\n\t\t\t\t\t\thaving _etm_lang ne ' ';\n\t\trun;\n\n\t\tproc sql noprint;\n\t\t\tselect distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n\t\t\t\tfrom work._etm_lang_grp\n\t\t\t\t\twhere _etm_lang ne ' ' and _etm_lang_cnt >= 50;\n\t\trun;\n\t\t\n\t\tods noproctitle;\n\t\n\t\t%do i=1 %to &_etm_lang_cnt.;\n\t\n\t\t\t* If the language split has to be created;\n\t\t\t%if not &profileText. and not &detectSentiment. and not &createPredefinedConcepts. and not &useCustomConcepts. %then %do;\n\t\t\t\t* Create a separate dataset for each language;\n\t\t\t\tdata _etm_cas._etm_lang_&&_etm_lang&i.;\n\t\t\t\t\tset &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n\t\t\t\trun;\n\t\t\t%end;\n\t\n\t\t\t* Load default stop lists;\n\t\t\tproc casutil;\n\t\t\t\tload casdata=\"&&_etm_lang&i.._stoplist.sashdat\" incaslib='referencedata'\n\t\t\t\t\tcasout=\"_etm_&&_etm_lang&i.._stoplist\" outcaslib='casuser' replace;\n\t\t\tquit;\n\n\t\t\tdata _null_;\n\t\t\t\tset work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n\t\t\t\tcall symputx('_etm_long_lang', _etm_long_lang);\n\t\t\trun;\n\t\n            %if &useBestPractise. %then %do;\n                * Create the text topics;\n                proc cas;\n                    session _etm_sess;\n\n                    output log;\n\n                    loadactionset 'textMining';\n\n                    tmMine /\n                        language = \"&_etm_long_lang.\"\n                        documents = \"_etm_lang_&&_etm_lang&i.\"\n                        text = \"&textCol_1_name_base.\"\n                        docid = \"_etm_ID\"\n\n                        stopList = {name = \"_etm_&&_etm_lang&i.._stoplist\"}\n                        nounGroups = False\n                        tagging = False\n                        entities = 'NONE'\n                        reduce = 4\n                        resolution = 'MED'\n                        rotate = 'VARIMAX'\n                        maxK = 100\n                        numLabels = 20\n\n                        %if &createScreePlotSVD. %then %do;\n                            s = {name = \"_etm_&&_etm_lang&i.._svds\", replace = True}\n                        %end;\n\n                        %if &useTopicCreationTbD. %then %do;\n                            parent = {name = \"_etm_parent_&&_etm_lang&i.\", replace = True}\n                            terms = {name = \"_etm_terms_&&_etm_lang&i.\", replace = True}\n                        %end;\n\n                        docPro = {name = \"_etm_&&_etm_lang&i.._doc_pro\", replace = True}\n                        topics = {name = \"_etm_&&_etm_lang&i.._topics\", replace = True};\n                run;\n            %end;\n            %else %do;\n                %if &selectEntities. %then %do;\n                    %if &createPredefinedConcepts. %then %do;\n                        data _null_;\n                            _etm_prcncpt_all = \"'\" || \"&conceptList_1.\" || \"'\"\n                            %do j = 1 %to &conceptList_count.;\n                                || \",'\" || \"&&conceptList_&j.\" || \"'\"\n                            %end;\n                            ;\n                            call symputx('_etm_prcncpt_all', _etm_prcncpt_all);\n                        run;\n                    %end;\n                    %if &useCustomConcepts. %then %do;\n                        proc sql noprint;\n                            select distinct _etm_custom_concept into :_etm_custom_concept_1-\n                                from work._etm_all_custom_concepts;\n                \n                            select count(distinct _etm_custom_concept) into :_etm_custom_concept_cnt\n                                from work._etm_all_custom_concepts;\n                        run;\n                \n                        data _null_;\n                            _etm_custcncpt_all = \"'\" || \"&_etm_custom_concept_1.\" || \"'\"\n                            %do j = 1 %to &_etm_custom_concept_cnt.;\n                                || \",'\" || \"&&_etm_custom_concept_&j.\" || \"'\"\n                            %end;\n                            ;\n                            call symputx('_etm_custcncpt_all', _etm_custcncpt_all);\n                        run;\n                    %end;\n                %end;\n            \n                proc cas;\n\n                    session _etm_sess;\n\n                    output log;\n\n                    loadactionset 'textMining';\n            \n                    action tmMine;\n                        param\n                            language = \"&_etm_long_lang.\"\n                            documents = {name = \"_etm_lang_&&_etm_lang&i.\"}\n                            docId = \"_etm_ID\"\n            \n                            entities = %if &extractEntities. %then %do; 'std' %end;\n                            %else %do; 'none' %end;\n            \n                            noungroups = %if &posTagging. %then %do; True %end;\n                            %else %do; False %end;\n            \n                            stemming = %if &stemTerms. %then %do; True %end;\n                            %else %do; False %end;\n                            \n                            tagging = %if &extractNounGroups. %then %do; True %end;\n                            %else %do; False %end;\n            \n                            reduce = &minOccKeep.\n            \n                            cellWeight = %if &cellWeight. %then %do; 'log' %end;\n                            %else %do; 'none' %end;\n            \n                            termWeight = \"&termWeight.\"\n            \n                            %if &useStopWords. %then %do;\n                                stopList = {name = \"_etm_&&_etm_lang&i.._stoplist\"}\n                            %end;\n            \n                            norm = \"&normProjects.\"\n                            \n                            %if &numTopics. %then %do;\n                                k = &numTopicsK.\n                            %end;\n                            %else %do;\n                                maxK = &numTopicsMaxK.\n                            %end;\n            \n                            resolution = \"&resolutionLevel.\"\n            \n                            rotate = \"&rotationType.\"\n            \n                            numLabels = &numLabels.\n            \n                            %if &selectEntities. %then %do;\n                                selectEntity={tagList={\n                                    %if &createPredefinedConcepts. and &useCustomConcepts. %then %do;\n                                        &_etm_prcncpt_all., &_etm_custcncpt_all.\n                                    %end;\n                                    %else %if &createPredefinedConcepts. %then %do;\n                                        &_etm_prcncpt_all.\n                                    %end;\n                                    %else %do;\n                                        &_etm_custcncpt_all.\n                                    %end;\n                                }}\n            \n                                %if &useCustomConcepts. %then %do;\n                                    defaultEntitiesPriority = &defaultEntityPrio.\n\n                                    liti={name='_etm_custom_concept',\n                                    computedVars={name='_priority_'}\n                                    %if not &hasCustomPrio. %then %do;\n                                        , computedVarsProgram=\"_priority_ = %sysevalf(&defaultEntityPrio. + 1);\"\n                                    %end;\n                                    }\n                                %end;\n                            %end;\n\n                            text = \"&textCol_1_name_base.\"\n\n                            %if &createScreePlotSVD. %then %do;\n                                s = {name = \"_etm_&&_etm_lang&i.._svds\", replace = True}\n                            %end;\n\n                        \t%if &useTopicCreationTbD. %then %do;\n                            \tparent = {name = \"_etm_parent_&&_etm_lang&i.\", replace = True}\n                            \tterms = {name = \"_etm_terms_&&_etm_lang&i.\", replace = True}\n                        \t%end;\n\n                            docPro = {name = \"_etm_&&_etm_lang&i.._doc_pro\", replace = True}\n                            topics = {name = \"_etm_&&_etm_lang&i.._topics\", replace = True};\n                        run;\n                quit;\n            %end;\n\t\n\t\t\t%if &createScreePlotSVD. %then %do;\n\t\t\t\tods graphics / reset imagemap;\n\t\t\t\ttitle3 \"Scree Plot of SVD for &&_etm_lang&i.\";\n\t\t\t\tproc sgplot data = _etm_cas._etm_&&_etm_lang&i.._svds;\n\t\t\t\t    vline _id_ / \n                        response = _s_\n                        nostatlabel \n                        stat = Mean \n                        markers;\n\t\t\t\t    xaxis label='Topic';\n\t\t\t\t    yaxis grid label='Singular Value';\n\t\t\t\trun;\n\t\t\t\ttitle3;\n\t\t\t%end;\n\t\n\t\t\tproc sort data=_etm_cas._etm_&&_etm_lang&i.._doc_pro out=work._etm_&&_etm_lang&i.._doc_pro;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\n\t\t\t%let _etm_dsid=%sysfunc(open(work._etm_&&_etm_lang&i.._doc_pro));\n\t\t\t%let _etm_n=%sysfunc(attrn(&_etm_dsid., nvars));\n\n\t\t\t* Rename the topic columns to start with _etm_;\n\t\t\tdata work._etm_&&_etm_lang&i.._doc_pro(rename=(_etm__etm_id=_etm_id));\n\t\t\t\tset work._etm_&&_etm_lang&i.._doc_pro(rename=(\n\n\t\t\t\t%do j = 1 %to &_etm_n.;\n\t\t\t\t\t%let _etm_var=%sysfunc(varname(&_etm_dsid., &j.));\n\t\t\t\t\t&_etm_var. = _etm_&&_etm_lang&i._&_etm_var.\n\t\t\t\t%end;));\n\n\t\t\t\t%let _etm_rc=%sysfunc(close(&_etm_dsid.));\n\t\t\trun;\n\n\t\t\tdata &outTable.;\n\t\t\t\tmerge &outTable. work._etm_&&_etm_lang&i.._doc_pro;\n\t\t\t\tby _etm_ID;\n\t\t\trun;\n\n\t\t\t* Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_lang_grp _etm_&&_etm_lang&i.._doc_pro;\n\t\t\trun; quit;\n\n\t\t\tods proctitle;\n\t\t%end;\n\t%mend _etm_topic_discovery;\n\n\t%_etm_topic_discovery;\n\n\t* Remove the macro;\n\tproc catalog cat=work.sasmacr;\n\t\tdelete _etm_topic_discovery.macro;\n\trun; quit;\n%end;\n\n* Create BoolRules for a target variable associated wiht the text;\n%if &createBoolRules. %then %do;\n    %macro _etm_create_boolRule;\n\n        ods noproctitle;\n\n\t\t* Select all distinct languages in the dataset;\n\t\t* Filter languages that have more then 50 rows;\n\t\tproc sql noprint;\n\t\t\tcreate table work._etm_lang_grp as\n\t\t\tselect count(_etm_lang) as _etm_lang_cnt, _etm_lang\n\t\t\t\tfrom &outTable.\n\t\t\t\t\tgroup by _etm_lang\n\t\t\t\t\t\thaving _etm_lang ne ' ';\n\t\trun;\n\n\t\tproc sql noprint;\n\t\t\tselect distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n\t\t\t\tfrom work._etm_lang_grp\n\t\t\t\t\twhere _etm_lang ne ' ' and _etm_lang_cnt >= 50;\n\t\trun;\n        \n        %do i=1 %to &_etm_lang_cnt.;\n            * If the language split has to be created;\n            %if not &profileText. and not &detectSentiment. and not &createPredefinedConcepts. and not &useCustomConcepts. and not &createTopics. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n                run;\n            %end;\n\n            * Load the stop word list if it not loaded already;\n            %if not &createTopics. %then %do;\n                * Load default stop lists;\n                proc casutil;\n                    load casdata=\"&&_etm_lang&i.._stoplist.sashdat\" incaslib='referencedata'\n                        casout=\"_etm_&&_etm_lang&i.._stoplist\" outcaslib='casuser' replace;\n                quit;\n            %end;\n\n            options label;\n\n            * If the user does jas a termByDoc and terms from a previous topic creation step;\n            %if not &useTopicCreationTbD. %then %do;\n                proc cas;\n                    session _etm_sess;\n\n                    output log;\n\n                    loadactionset 'textMining';\n\n                    tmMine /\n                        documents = \"_etm_lang_&&_etm_lang&i.\"\n                        text = \"&textCol_1_name_base.\"\n                        docid = \"_etm_ID\"\n                        parent = {name = \"_etm_parent_&&_etm_lang&i.\", replace = True}\n                        terms = {name = \"_etm_terms_&&_etm_lang&i.\", replace = True}\n                        stopList = {name = \"_etm_&&_etm_lang&i.._stoplist\"}\n                        nounGroups = False\n                        tagging = False;\n                run;\n            %end;\n\n            proc cas;\n                session _etm_sess;\n\n                output log;\n\n                loadactionset 'boolRule';\n\n                brTrain /\n                    table = \"_etm_parent_&&_etm_lang&i.\"\n                    docid = '_document_'\n                    termid = '_termnum_'\n\n                    gPositive = &gPosBR.\n                    mPositive = &mPosBR.\n                    gNegative = &gNegBR.\n                    mNegative = &mNegBR.\n\n                    minSupports = &minSupportsBR.\n                    maxCandidates = &maxCandidatesBR.\n                    maxTriesIn = &maxTriesInBR.\n                    maxTriesOut = &maxTriesOutBR.\n\n                    docinfo = {\n                        table = \"_etm_lang_&&_etm_lang&i.\",\n                        id = '_etm_ID',\n                        targetType = \"&boolRuleTargetType.\"\n                        targets = {\"&boolRuleTarget_1_name_base.\"}\n                    }\n\n                    termInfo = {table = \"_etm_terms_&&_etm_lang&i.\", id = '_termnum_', label = '_term_'}\n                    casOuts = {rules = {name = \"_etm_rules_&&_etm_lang&i.\", replace = True}\n                        ruleTerms = {name = \"_etm_ruleTerms_&&_etm_lang&i.\", replace = True}\n                        candidateTerms = {name = \"_etm_cnddtTerms_&&_etm_lang&i.\", replace = True}\n                    };\n            run;\n\n            proc sql noprint;\n                select _ruleid_,\n                    compress(translate(strip(_rule_),'|','&'),' ~')\n                    into : _etm_ranks separated by '|', : _etm_terms separated by '|'\n                    from _etm_cas._etm_rules_&&_etm_lang&i.\n                        order by _ruleid_;\n            quit;\n            \n            data work._etm_boolRule_base;\n                set &outTable.;\n            \n                %do j=1 %to &sqlobs.;\n                    _etm_BR_&j.=(find(&textCol_1_name_base.,\"%scan(&_etm_terms.,&j.,'|')\",'i') gt 0);\n                    Label _etm_BR_&j.=\"BoolRule_&j.: %scan(&_etm_terms.,&j.,'|')\";\n                %end;\n            run;\n            \n            proc sort data=work._etm_boolRule_base;\n                by _etm_ID;\n            run;\n\n            data &outTable.;\n                merge &outTable. work._etm_boolRule_base;\n                by _etm_ID;\n            run;\n            \n            proc sort data=_etm_cas._etm_rules_&&_etm_lang&i. out=work._etm_butterfly;\n                by _ruleid_;\n            run;\n            \n            data work._etm_butterfly;\n                retain lrecall;\n                set work._etm_butterfly;\n                \n                rPrecision = _RuleTP_ / _RuleSupport_;\n                if _n_ eq 1 then rRecall = _Recall_;\n                if _n_ gt 1 then rRecall = _Recall_ - lrecall;\n                lRecall = _Recall_;\n            run;\n            \n            data work._etm_butterfly;\n                set work._etm_butterfly;\n            \n                rPrecision = -rPrecision;\n                rRecall = -rRecall;\n                Zero = 0;\n                Rule1\t= strip(_rule_)||' ('||strip(put(_RuleSupport_, 8.))||')';\n            \n                call symputx('_etm_Precision', put(_Precision_, f4.2));\n                call symputx('_etm_Recall', put(_Recall_, f4.2));\n            run;\n            \n            proc format;\n                picture positive low-<0='0000'\n                    0<-high='0000';\n            run;\n            \n            Title1 \"Top 100 Boole Rules for Text Variable &textCol_1_name_base. and Target Variable &boolRuleTarget_1_name_base.\";\n            Title2 \"Filter Criteria: gPositive=&gPosBR. mPositive=&mPosBR. gNegative=&gNegBR. mNegative=&mNegBR.\";\n            \n            ods layout gridded columns = 2;\n            ods region;\n            ods graphics on / width = 800 Height = 1850;\n            proc sgplot data = work._etm_butterfly(obs = 100) noautolegend;\n            \n            Title \"Single Rule - Support - Cumul. Rule\";\n            footnote;\n            \n            format _Precision_ _Recall_ rPrecision rRecall positive.;\n            hbarparm category=rule1 response=_precision_ / dataskin=gloss name='Precision'\n                fillattrs=graphdata1  datalabelattrs=(size=10) transparency=0;\n            hbarparm category=rule1 response=rPrecision /  name='rPrecision'\n                fillattrs=graphdata1  datalabelattrs=(size=10) dataskin=gloss transparency=0;\n            hbarparm category=rule1 response=_Recall_ / dataskin=gloss name='Recall'\n                fillattrs=graphdata2  datalabelattrs=(size=10) transparency=0;\n            hbarparm category=rule1 response=rRecall / dataskin=gloss name='rRecall'\n                fillattrs=graphdata2  datalabelattrs=(size=10) transparency=0;\n            refline &_etm_Precision. / axis=x label=\"Cumultive Precision=&_etm_Precision.\"\n                labelloc=inside labelpos=min lineattrs=graphdata1;\n            refline &_etm_Recall. / axis=x label=\"Cumultive Recall=&_etm_Recall.\"\n                labelloc=inside labelpos=max  lineattrs=graphdata2;\n            scatter x=zero y=Rule1 / markerchar=Rule1 markercharattrs=(size=8  color=black);\n            keylegend 'Precision' 'Recall' 'F1';\n            xaxis values=(-1 to 1 by .2)  grid offsetmin=0.05 offsetmax=0.05 values=(-1 to 1 by .2) display=(nolabel)\n            Label='Single Prec & Rec - Rule(Support) - Cumul. Prec & Rec';\n            yaxis display=(noticks novalues nolabel);\n            scatter y=rule1 x=_f1_  / markerattrs=(Color=red symbol='CircleFilled' size=2) name=\"_F1_\" legendlabel=\"F1\";\n            run;\n            \n            data work._etm_butterfly;\n                set work._etm_butterfly;\n\n                rPrecision=-rPrecision;\n                rRecall=-rRecall;\n            run;\n            \n            ods region;\n            proc print data=work._etm_butterfly(Obs=100) label;\n                format rPrecision rRecall  _Precision_ _Recall_  _F1_ f5.3;\n                Id _RuleID_ _Rule_;\n                var rPrecision rRecall _RuleSupport_ _Precision_ _Recall_  _F1_ _RuleTP_ _RuleFP_  _RuleSetTP_ _RuleSetFP_ _RuleSetSupport_;\n            run;\n            ods layout end;\n            title;\n            ods;\n\n            * Remove datasets;\n\t\t\tproc datasets library=work nolist;\n\t\t\t\tdelete _etm_butterfly _etm_boolRule_base;\n\t\t\trun; quit;\n\n            * Remove the Custom Format;\n            proc catalog cat=work.formats;\n                delete positive / et=format;\n            run;\n        %end;\n    %mend _etm_create_boolRule;\n\n    %_etm_create_boolRule;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_create_boolRule.macro;\n    run; quit;\n\n%end;\n\n* This dataset is used by different actions that run for each language in the dataset;\n%if &profileText. or &createTopics. or &createPredefinedConcepts. or &useCustomConcepts. or &createBoolRules. %then %do;\n\t* Remove language translation dataset;\n\tproc datasets library=work nolist;\n\t\tdelete _etm_lang_trans;\n\trun; quit;\n%end;\n\n* This dataset is used by actions that levarage the custom concepts;\n%if &useCustomConcepts. %then %do;\n    * Remove datasets;\n    proc datasets library=work nolist;\n        delete _etm_all_custom_concepts;\n    run; quit;\n%end;\n\n%if &useTextAnalytics. %then %do;\n\t* End the CAS session;\n\tcas _etm_sess terminate;\n%end;"}}